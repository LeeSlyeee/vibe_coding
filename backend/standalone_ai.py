import requests
import re
import random

def generate_analysis_reaction_standalone(user_text, mode='reaction', history=None):
    print(f"DEBUG: generate_analysis_reaction_standalone called. Mode={mode}, HistoryLen={len(history) if history else 0}")
    if not user_text: return None
    
    # 1. Sanitize
    text = re.sub(r'[\w\.-]+@[\w\.-]+', '[EMAIL]', user_text)
    sanitized = text[:300]
    
    # 2. History Formatting
    context_str = ""
    if history:
        # history is expected to be a string or list of "User: ... / AI: ..."
        context_str = f"### [ì´ì „ ëŒ€í™” ê¸°ë¡]\n{history}\n\n"

    # 3. Prompt Switching
    # Combined Prompt for continuous conversation
    prompt_text = (
        f"ë„ˆëŠ” ë‹¤ì •í•˜ê³  í†µì°°ë ¥ ìˆëŠ” 'ì‹¬ë¦¬ ìƒë‹´ì‚¬'ì•¼.\n"
        f"{context_str}"
        f"### [ë‚´ë‹´ìì˜ í˜„ì¬ ë§]: \"{sanitized}\"\n\n"
        "### [ì§€ì‹œì‚¬í•­]:\n"
        "1. ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ìˆë‹¤ë©´ ê·¸ íë¦„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì„œ ë‹µë³€í•´.\n"
        "2. ë‚´ë‹´ìì˜ ê°ì •ì„ ì½ì–´ì£¼ê³ , ê·¸ ë§ì´ íƒ€ë‹¹í•¨ì„ ì§€ì§€í•´ì¤˜.\n"
        "3. ë”±ë”±í•œ ë¶„ì„ë³´ë‹¤ëŠ”, ì˜†ì—ì„œ ì´ì•¼ê¸°í•˜ë“¯ ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ¬ìš´ 'í•´ìš”ì²´'ë¥¼ ì‚¬ìš©í•´.\n"
        "4. í˜¼ì ë– ë“¤ì§€ ë§ê³ , ë‚´ë‹´ìê°€ ì´ì•¼ê¸°ë¥¼ ê³„ì† í•  ìˆ˜ ìˆë„ë¡ ì´ëŒì–´ì¤˜.\n"
        "5. 150ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ.\n\n"
        "ìƒë‹´ì‚¬ ë‹µë³€:"
    )
    
    input_len = len(user_text)
    dynamic_tokens = 800 # Default Base (Increased)
    
    if input_len < 50:
        dynamic_tokens = 500  # ì§§ì€ ì§ˆë¬¸ë„ ì¶©ë¶„íˆ
    elif input_len > 200:
        dynamic_tokens = 1200 # ê¸´ ê³ ë¯¼ì€ ì•„ì£¼ ê¸¸ê²Œ (ì•½ 3~4ë¬¸ë‹¨ ê°€ëŠ¥)
        
    print(f"ğŸ“ [Auto-Scale] Input: {input_len} chars -> Allocating {dynamic_tokens} tokens")

    try:
        payload = {
            "model": "maum-on-gemma",
            "prompt": prompt_text,
            "stream": False,
            "options": {
                "temperature": 0.7, 
                "num_predict": dynamic_tokens
            }
        }
        res = requests.post("http://localhost:11434/api/generate", json=payload, timeout=120)
        
        if res.status_code == 200:
            result = res.json().get('response', '').strip()
            if result.startswith('"') and result.endswith('"'):
                result = result[1:-1]
            if result: return result
            
    except Exception as e:
        print(f"âŒ Standalone AI Error: {e}")
        
    # 3. Fallback (Mode Specific)
    fallbacks = []
    if mode == 'question':
        fallbacks = [
            "ê·¸ë ‡êµ°ìš”. í˜¹ì‹œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ê¶ê¸ˆí•´ìš”.",
            "ì €ëŸ°, íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆì—ˆëŠ”ì§€ ë“£ê³  ì‹¶ì–´ìš”.",
            "ì§§ê²Œ ë§ì”€í•˜ì‹œë‹ˆ ë” ê¹Šì€ ì†ë§ˆìŒì´ ê¶ê¸ˆí•´ì§€ë„¤ìš”. í¸í•˜ê²Œ í„¸ì–´ë†“ì•„ì£¼ì„¸ìš”.",
            "ê·¸ ì¼ì´ ë‚´ë‹´ìë‹˜ê»˜ ì–´ë–¤ ì˜ë¯¸ì˜€ëŠ”ì§€ ì¡°ê¸ˆë§Œ ë” ë“¤ë ¤ì£¼ì„¸ìš”."
        ]
    else:
        fallbacks = [
            "ë§ì”€í•˜ì‹  ë‚´ìš©ì—ì„œ ê¹Šì€ ê³ ë¯¼ê³¼ ì§„ì‹¬ì´ ëŠê»´ì§€ë„¤ìš”. ì˜í•˜ê³  ê³„ì‹­ë‹ˆë‹¤.",
            "ìƒí™©ì„ ì°¨ë¶„íˆ ë“¤ì—¬ë‹¤ë³´ë©´, ê·¸ ì•ˆì—ì„œ ìŠ¤ìŠ¤ë¡œì˜ ì„±ì¥ì„ ë°œê²¬í•˜ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.",
            "ì§€ê¸ˆ ëŠë¼ì‹œëŠ” ê°ì •ì€ ë§¤ìš° ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì´ì—ìš”. ìŠ¤ìŠ¤ë¡œë¥¼ ë¯¿ì–´ë³´ì„¸ìš”.",
            "ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ë³´ë‹ˆ, ê·¸ë™ì•ˆ ë§ˆìŒì†ì— ë‹´ì•„ë‘ì…¨ë˜ ìƒê°ë“¤ì´ ë§ìœ¼ì…¨ë˜ ê²ƒ ê°™ì•„ ë§ˆìŒì´ ì“°ì´ë„¤ìš”."
        ]
        
    return random.choice(fallbacks)

def analyze_chat_sentiment_background(user_text, ai_reaction):
    """
    Background Task: Analyze the chat turn to extract structured psychological data.
    Returns a dict with:
    - primary_emotion (str)
    - stress_level (int 1-10)
    - risk_flag (bool)
    - keywords (list)
    """
    print(f"DEBUG: Analyzing chat sentiment for: {user_text[:20]}...")
    if not user_text: return None
    
    # Sanitize
    sanitized = re.sub(r'[\w\.-]+@[\w\.-]+', '[EMAIL]', user_text)[:500]
    
    prompt_text = (
        f"ë¶„ì„í•  ë°œí™”:\n"
        f"ë‚´ë‹´ì: \"{sanitized}\"\n"
        f"ìƒë‹´ì‚¬ ë°˜ì‘: \"{ai_reaction[:100]}...\"\n\n"
        "ìœ„ ë‚´ë‹´ìì˜ ë°œí™”ë¥¼ ì‹¬ë¦¬í•™ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ **JSON í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì‹œì˜¤.\n"
        "ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹œì˜¤.\n\n"
        "{\n"
        "  \"primary_emotion\": \"(60ê°€ì§€ ê°ì • ì¤‘ ê°€ì¥ í•µì‹¬ì ì¸ ê°ì • ë‹¨ì–´ 1ê°œ, í•œêµ­ì–´)\",\n"
        "  \"stress_level\": (1~10 ì‚¬ì´ ì •ìˆ˜, ë†’ì„ìˆ˜ë¡ ìŠ¤íŠ¸ë ˆìŠ¤ ì‹¬í•¨),\n"
        "  \"risk_flag\": (ìì‚´, ìí•´, íƒ€í•´ ìœ„í—˜ì´ ê°ì§€ë˜ë©´ true, ì•„ë‹ˆë©´ false),\n"
        "  \"keywords\": [\"(í•µì‹¬ í‚¤ì›Œë“œ 1)\", \"(í•µì‹¬ í‚¤ì›Œë“œ 2)\"]\n"
        "}"
    )
    
    try:
        payload = {
            "model": "maum-on-gemma",
            "prompt": prompt_text,
            "stream": False,
            "options": {
                "temperature": 0.2, # Low temp for consistent JSON
                "num_predict": 120
            }
        }
        res = requests.post("http://localhost:11434/api/generate", json=payload, timeout=30)
        
        if res.status_code == 200:
            result_str = res.json().get('response', '').strip()
            # Extract JSON block if wrapped in code fences
            if "```json" in result_str:
                import re
                match = re.search(r"```json(.*?)```", result_str, re.DOTALL)
                if match: result_str = match.group(1)
            elif "```" in result_str:
                 match = re.search(r"```(.*?)```", result_str, re.DOTALL)
                 if match: result_str = match.group(1)

            import json
            data = json.loads(result_str)
            print(f"âœ… Chat Analysis Result: {data}")
            return data
            
    except Exception as e:
        print(f"âŒ Chat Analysis Error: {e}")
        return {
            "primary_emotion": "ë¶„ì„ ì‹¤íŒ¨",
            "stress_level": 0,
            "risk_flag": False,
            "keywords": []
        }
