
import os
import time

class VoiceBrain:
    def __init__(self, model_size="small", device="cpu", compute_type="int8"):
        self.model_size = model_size
        self.device = device
        self.compute_type = compute_type
        self.model = None
        self.is_loading = False

    def load_model(self):
        if self.model is None and not self.is_loading:
            self.is_loading = True
            try:
                print(f"ğŸ™ï¸ Loading Faster-Whisper Model ({self.model_size}) on {self.device}...")
                from faster_whisper import WhisperModel
                # model_size can be "tiny", "base", "small", "medium", "large-v3"
                self.model = WhisperModel(
                    self.model_size, 
                    device=self.device, 
                    compute_type=self.compute_type
                )
                print("âœ… Faster-Whisper Model Loaded.")
            except Exception as e:
                print(f"âŒ Failed to load Whisper: {e}")
                self.model = None
            finally:
                self.is_loading = False

    def transcribe(self, audio_path):
        if self.model is None:
            self.load_model()
            if self.model is None:
                return "ìŒì„± ì¸ì‹ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨"

        try:
            start_time = time.time()
            segments, info = self.model.transcribe(
                audio_path, 
                beam_size=5, 
                language="ko",
                vad_filter=True # Filter silence
            )
            
            print(f"Detected language '{info.language}' with probability {info.language_probability:.2f}")

            full_text = ""
            for segment in segments:
                full_text += segment.text + " "
            
            print(f"ğŸ™ï¸ Transcription took {time.time() - start_time:.2f}s")
            return full_text.strip()
        except Exception as e:
            print(f"âŒ Transcription Error: {e}")
            return "ìŒì„± ì¸ì‹ ì˜¤ë¥˜ ë°œìƒ"

    def structure_diary_text(self, text):
        """
        Uses Local LLM (Gemma 2) to split the transcribed text into diary fields.
        Returns a dict with keys: event, emotion, meaning, comfort.
        """
        import requests
        import json
        import re

        if not text or len(text) < 5:
            return None

        print(f"ğŸ§  [VoiceBrain] Structuring text with Gemma 2...")
        
        try:
            url = "http://localhost:11434/api/generate"
            prompt_text = (
                f"### Role\n"
                f"ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì¼ê¸° ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ ë¶„ë¥˜í•´ì£¼ëŠ” AI ë¹„ì„œì…ë‹ˆë‹¤.\n\n"
                f"### Input Text\n"
                f"{text}\n\n"
                f"### Task\n"
                f"ìœ„ ë‚´ìš©ì„ ë‹¤ìŒ 4ê°€ì§€ í•­ëª©ìœ¼ë¡œ ì ì ˆíˆ ë‚˜ëˆ„ê±°ë‚˜ ìš”ì•½í•´ì„œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.\n"
                f"1. event: ì˜¤ëŠ˜ ìˆì—ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ê±´/ì‚¬ì‹¤\n"
                f"2. emotion: ê·¸ ì‚¬ê±´ìœ¼ë¡œ ì¸í•´ ëŠë‚€ ê°ì •\n"
                f"3. meaning: ê·¸ ê°ì •ì´ ìì‹ ì—ê²Œ ì£¼ëŠ” ì˜ë¯¸ë‚˜ ê¹Šì€ ìƒê° (ì—†ë‹¤ë©´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì¶”ë¡ )\n"
                f"4. comfort: ìì‹ ì—ê²Œ í•´ì£¼ê³  ì‹¶ì€ ìœ„ë¡œì˜ ë§ (ì—†ë‹¤ë©´ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ë”°ëœ»í•˜ê²Œ ì‘ì„±)\n\n"
                f"### Output Format (Strict JSON)\n"
                f"{{\n"
                f"  \"event\": \"...\",\n"
                f"  \"emotion\": \"...\",\n"
                f"  \"meaning\": \"...\",\n"
                f"  \"comfort\": \"...\"\n"
                f"}}\n"
                f"* ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ì¡ë‹´ ê¸ˆì§€."
            )

            payload = {
                "model": "gemma2:2b",
                "prompt": prompt_text,
                "stream": False,
                "format": "json", # Enforce structured mode
                "options": {
                    "temperature": 0.5,
                    "num_predict": 500
                }
            }
            
            response = requests.post(url, json=payload, timeout=60)
            if response.status_code != 200:
                print(f"âŒ LLM Error: {response.text}")
                return None
                
            json_str = response.json().get('response', '')
            print(f"ğŸ§  [VoiceBrain] Raw LLM Response: {json_str[:100]}...")
            
            # Simple Cleaning just in case
            try:
                data = json.loads(json_str)
                return {
                    "question1": data.get("event", ""),
                    "question2": data.get("emotion", ""),
                    "question3": data.get("meaning", ""),
                    "question4": data.get("comfort", "")
                }
            except json.JSONDecodeError:
                print("âŒ Failed to parse JSON from LLM")
                return None

        except Exception as e:
            print(f"âŒ Structure Error: {e}")
            return None

# Global Instance
voice_brain_instance = VoiceBrain()
