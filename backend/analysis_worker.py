import threading
import psycopg2
import requests
import json
import os
import re
import logging
import ast # Added for safe literal eval
from dotenv import load_dotenv
from crypto_utils import EncryptionManager

load_dotenv()

# PG Config
DB_NAME = "vibe_db"
DB_USER = "vibe_user"
DB_PASS = "vibe1234"
DB_HOST = "127.0.0.1"


crypto = EncryptionManager(os.environ.get('ENCRYPTION_KEY'))

# RunPod Config
RUNPOD_API_KEY = os.getenv('RUNPOD_API_KEY')
RUNPOD_LLM_URL = os.getenv('RUNPOD_LLM_URL')

def call_llm_hybrid(prompt, model="maumON-gemma:latest", options=None):
    """
    Hybrid LLM Caller: RunPod (Priority) -> Local Ollama (Fallback)
    """
    if options is None: options = {}
    
    logging.info(f"ğŸ” Hybrid Check: KEY_LEN={len(str(RUNPOD_API_KEY)) if RUNPOD_API_KEY else 0}, URL={RUNPOD_LLM_URL}")
    
    import time

    # 1. Try RunPod Serverless (Priority)
    # The URL in .env should be base endpoint: https://api.runpod.ai/v2/mp2w6kb0npg0tp
    if RUNPOD_API_KEY and RUNPOD_LLM_URL and "YOUR_POD_ID" not in RUNPOD_LLM_URL:
        try:
            logging.info("ğŸš€ Sending Async request to RunPod Serverless...")
            
            # Normalize Base URL (Remove /runsync or /run)
            base_url = RUNPOD_LLM_URL.replace('/runsync', '').replace('/run', '').rstrip('/')
            
            # 1. Submit Job
            submit_url = f"{base_url}/run"
            headers = {
                "Authorization": f"Bearer {RUNPOD_API_KEY}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "input": {
                    "prompt": prompt,
                    "max_tokens": options.get('num_predict', 512),
                    "temperature": options.get('temperature', 0.7),
                    "stream": False
                }
            }
            
            res = requests.post(submit_url, json=payload, headers=headers, timeout=30)
            if res.status_code != 200:
                logging.error(f"âŒ RunPod Submit Failed {res.status_code}: {res.text}")
                raise Exception("RunPod Submit Failed")
                
            job_id = res.json()['id']
            logging.info(f"â³ Job Submitted: {job_id}. Polling status...")
            
            # 2. Poll Status
            status_url = f"{base_url}/status/{job_id}"
            start_time = time.time()
            
            while True:
                if time.time() - start_time > 300: # 5 min timeout
                    raise Exception("RunPod Job Timed Out")
                    
                status_res = requests.get(status_url, headers=headers, timeout=30)
                status_data = status_res.json()
                status = status_data.get('status')
                
                if status == 'COMPLETED':
                    output = status_data.get('output')
                    logging.info("âœ… RunPod Job Completed!")
                    
                    # Process Output
                    if isinstance(output, dict):
                         if 'reaction' in output:
                             # Clean Markdown tokens if present
                             clean_str = output['reaction'].strip()
                             if clean_str.startswith('```'):
                                 clean_str = re.sub(r'^```(?:json)?\s*|\s*```$', '', clean_str, flags=re.MULTILINE)
                             clean_str = clean_str.strip()
                             
                             try:
                                 inner = json.loads(clean_str)
                             except:
                                 try:
                                     inner = ast.literal_eval(clean_str)
                                 except:
                                     # Regex Fallback
                                     emo_match = re.search(r'["\']emotion["\']\s*:\s*["\']((?:[^"\\]|\\.)*)["\']', clean_str)
                                     com_match = re.search(r'["\']comment["\']\s*:\s*["\']((?:[^"\\]|\\.)*)["\']', clean_str)
                                     if emo_match and com_match:
                                         inner = {"emotion": emo_match.group(1), "comment": com_match.group(1)}
                                     else:
                                         inner = None
                                     
                             if isinstance(inner, dict):
                                 content = json.dumps(inner, ensure_ascii=False)
                             else:
                                 content = output['reaction']
                         elif 'text' in output:
                             content = output['text']
                         elif 'response' in output:
                             content = output['response']
                         else:
                             content = json.dumps(output, ensure_ascii=False)
                    else:
                         content = str(output)
                    
                    return content
                    
                elif status in ['FAILED', 'CANCELLED']:
                    logging.error(f"âŒ RunPod Job Failed: {status}")
                    raise Exception(f"RunPod Job {status}")
                
                # Wait before polling again
                time.sleep(2)
                
        except Exception as e:
            logging.error(f"âŒ RunPod Async Failed: {e}")
            # Fallthrough to Local

    # 2. Local Ollama (Fallback)
    try:
        logging.info("â³ Sending request to Local Ollama...")
        payload = {
            "model": model,
            "prompt": prompt,
            "stream": False,
            "format": "json" if options.get('format') == 'json' else "",
            "options": options
        }
        # Increased timeout for CPU (Long generation needs more time)
        # 180 -> 300 seconds (5 minutes)
        res = requests.post("http://localhost:11434/api/generate", json=payload, timeout=300)
        
        logging.info(f"âœ… Ollama Response: {res.status_code}")
        if res.status_code == 200:
            return res.json().get('response', '').strip()
            
    except Exception as e:
         logging.error(f"âŒ Local Ollama Failed: {e}")
         raise e
         
    return None


def generate_ai_analysis(content):
    prompt_text = (
        f"ë„ˆëŠ” ë‹¤ì •í•˜ê³  ì„¬ì„¸í•œ ì‹¬ë¦¬ ìƒë‹´ AI 'ë§ˆìŒì˜¨'ì´ì•¼. ì•„ë˜ íšŒì›ì˜ ì¼ê¸°ë¥¼ ì½ê³  ë¶„ì„ ê²°ê³¼ë¥¼ JSON í˜•íƒœë¡œ ì¤˜.\n"
        f"{content}\n\n"
        "### ì§€ì‹œì‚¬í•­:\n"
        "1. 'comment': íšŒì›ì˜ ê°ì •ì„ ì½ê³  ë”°ëœ»í•˜ê²Œ ìœ„ë¡œí•˜ëŠ” ë§ (í•´ìš”ì²´, 150ì ë‚´ì™¸)\n"
        "2. 'emotion': íšŒì›ì˜ í˜„ì¬ ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” **ë‹¨ í•˜ë‚˜ì˜ í•µì‹¬ ë‹¨ì–´** (ì˜ˆ: ë¶ˆì•ˆí•¨, ì„¤ë ˜, í™€ê°€ë¶„í•¨, ë‹µë‹µí•¨)\n"
        "3. 'score': íšŒì›ì˜ ê°ì • ìƒíƒœë¥¼ **1ì (ë§¤ìš° ë‚˜ì¨/ìš°ìš¸)**ì—ì„œ **10ì (ë§¤ìš° ì¢‹ìŒ/í–‰ë³µ)** ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ í‰ê°€í•´.\n"
        "4. ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•´.\n\n"
        "{\n"
        '  "emotion": "í•µì‹¬ê°ì •ë‹¨ì–´",\n'
        '  "comment": "ìœ„ë¡œì˜ ë©”ì‹œì§€...",\n'
        '  "score": 5\n'
        "}"
    )
    
    try:
        options = {"temperature": 0.7, "num_predict": 500, "format": "json"}
        
        raw = call_llm_hybrid(prompt_text, options=options)
        
        if raw:
             # Try parse JSON
             try:
                 data = json.loads(raw)
                 comment = data.get('comment', '')
                 emotion = data.get('emotion', '')
                 score = data.get('score', 5)

                 # [Fix] Fallback for empty emotion
                 if not emotion:
                     if score >= 8: emotion = "í–‰ë³µ"
                     elif score >= 6: emotion = "ê¸°ì¨"
                     elif score >= 5: emotion = "í‰ì˜¨"
                     elif score >= 3: emotion = "ë¶ˆì•ˆ"
                     else: emotion = "ìš°ìš¸"
                 
                 return comment, emotion, score
             except Exception as e:
                 print(f"âš ï¸ JSON Parse Failed. Error: {e} | Raw: {raw}")
                 # Try to salvage raw text if it looks like a comment
                 if len(raw) > 10 and "{" not in raw:
                     return raw, "ë¶„ì„ì¤‘", 5
                 return raw, "ë¶„ì„ì¤‘", 5
    except Exception as e:
        print(f"âŒ AI Gen Error: {e}")
    return "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ê¹Šì´ ì‘ì›í•©ë‹ˆë‹¤. (AI ë¶„ì„ ì§€ì—°)", "ëŒ€ê¸°ì¤‘", 5


# Set up logging
logging.basicConfig(
    filename='ai_worker.log', 
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

def run_analysis_process(diary_id, date, event, sleep, emotion_desc, emotion_meaning, self_talk):
    logging.info(f"ğŸ§µ [Thread] Starting Analysis for Diary {diary_id}...")
    print(f"ğŸ§µ [Thread] Starting Analysis for Diary {diary_id}...")
    
    # 1. Generate Comment & Emotion & Score
    full_text = f"ë‚ ì§œ: {date}\nìˆ˜ë©´: {sleep}\nì‚¬ê±´: {event}\nê°ì •: {emotion_desc}\nì˜ë¯¸: {emotion_meaning}\nìŠ¤ìŠ¤ë¡œì—ê²Œ: {self_talk}"
    # Remove None or empty strings from formatting if needed, but simple string interpolation is fine
    
    comment, emotion, score = generate_ai_analysis(full_text)
    
    # ... (rest is same, but let's include it to be safe or use Context)
    print(f"ğŸ¤– AI Result - Score: {score}, Emotion: {emotion}, Comment: {comment[:20]}...")

    # 2. Encrypt
    enc_comment = crypto.encrypt(comment)
    enc_emotion = crypto.encrypt(emotion)
    
    # 3. Update DB
    # 3. Update DB
    try:
        db_url = os.environ.get('DATABASE_URL')
        if db_url:
            conn = psycopg2.connect(db_url)
        else:
            conn = psycopg2.connect(dbname=DB_NAME, user=DB_USER, password=DB_PASS, host=DB_HOST)
        # conn.autocommit = True # [Fix] Use manual commit for rollback safety
        cur = conn.cursor()
        
        # Ensure score is integer and within range
        try:
            score = int(score)
            score = max(1, min(10, score))
        except:
            score = 5

        # [Resilient Update Strategy]
        # Try 'mood_score' first (Legacy/Current Schema?)
        try:
            cur.execute(
                "UPDATE diaries SET ai_comment = %s, ai_emotion = %s, mood_score = %s WHERE id = %s", 
                (enc_comment, enc_emotion, score, diary_id)
            )
            conn.commit()
            print(f"âœ… [Thread] Database Updated (mood_score)")
        except Exception as e:
            conn.rollback()
            print(f"âš ï¸ [Thread] 'mood_score' update failed, trying 'mood_intensity': {e}")
            
            # Try 'mood_intensity' (Models.py Schema)
            try:
                cur.execute(
                    "UPDATE diaries SET ai_comment = %s, ai_emotion = %s, mood_intensity = %s WHERE id = %s", 
                    (enc_comment, enc_emotion, score, diary_id)
                )
                conn.commit()
                print(f"âœ… [Thread] Database Updated (mood_intensity)")
            except Exception as e2:
                conn.rollback()
                print(f"âš ï¸ [Thread] 'mood_intensity' update failed, fallback to basic update: {e2}")
                
                # Fallback: Update only AI fields
                cur.execute(
                    "UPDATE diaries SET ai_comment = %s, ai_emotion = %s WHERE id = %s", 
                    (enc_comment, enc_emotion, diary_id)
                )
                conn.commit()
                print(f"âœ… [Thread] Database Updated (Basic)")
        
        print(f"âœ… [Thread] Analysis Complete for Diary {diary_id}")
        cur.close()
        conn.close()
    except Exception as e:
        print(f"âŒ [Thread] Final DB Update Failed: {e}")

def start_analysis_thread(diary_id, date, event, sleep, emotion_desc, emotion_meaning, self_talk):
    print(f"ğŸ§µ [Main] Spawning Analysis Thread for Diary {diary_id}")
    logging.info(f"ğŸ§µ [Main] Spawning Analysis Thread for Diary {diary_id}")
    t = threading.Thread(target=run_analysis_process, args=(diary_id, date, event, sleep, emotion_desc, emotion_meaning, self_talk))
    t.start()
