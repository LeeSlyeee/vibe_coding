# Mood Diary AI 백엔드

무드 다이어리(Mood Diary) 애플리케이션을 위한 Flask 기반 백엔드로, 고급 감정 분석 및 공감형 AI 코멘트 생성 기능을 특징으로 합니다.

## 🚀 주요 기능

### 1. 감정 분석 (LSTM)

- **모델**: 128 유닛을 가진 양방향 LSTM (Bidirectional LSTM).
- **클래스**: 5가지 감정 (행복해, 평온해, 그저그래, 우울해, 화가나).
- **훈련 데이터**: 약 47,000개의 결합된 데이터셋.
  - `GoEmotions-Korean`: 50,000개 이상의 라벨링된 문장 (Google).
  - `감성대화말뭉치`: 36,000개 이상의 대화 쌍 (AI Hub).
  - `User Data`: 10,000개 이상의 실제 일기 데이터 (파인 튜닝).
- **성능**: 저장된 모델(`emotion_model.h5`)을 통해 높은 정확도 제공.

### 2. 생성형 AI 코멘트 (고급 하이브리드 시스템)

- **시스템**: 3단계 우선순위 아키텍처.
  1.  **안전장치 (규칙 기반)**: "시험", "이별"과 같은 중요 키워드에 대해 즉각적이고 높은 품질의 조언 제공.
  2.  **KoGPT-2 (LLM)**: SKT의 `kogpt2-base-v2` 모델을 사용하여 창의적이고 시적인 답변 생성.
  3.  **Seq2Seq (대체 모델)**: 경량 백업 모델.
- **기능**: 사용자 일기를 바탕으로 공감하고 맥락을 파악하여 조언 생성.
- **최적화**: 효율적인 한국어 토큰화를 위해 `PreTrainedTokenizerFast` 사용.
- **파일**: `comment_bank.json` (규칙), `comment_model.h5` (레거시).

### 3. 능동형 학습 및 키워드 추출

- **키워드 추출**: 사용자 일기에서 감정별 키워드를 자동으로 학습.
- **지식 베이스**: `EmotionKeyword` 테이블에 현재 **30,000개 이상의 학습된 키워드** 보유.
- **지속적 학습**: 일기 데이터가 쌓일수록 시스템의 성능이 향상됨.

---

## 🛠 설정 및 실행

### A. 환경 설정

```bash
cd backend
source venv/bin/activate
```

### B. 서버 실행

```bash
python app.py
```

- 서버는 `http://127.0.0.1:5000`에서 시작됩니다.
- API 문서: `app.py`의 `/api/` 엔드포인트를 참조하세요.

### C. 스크립트를 통한 AI 관리

- **전체 모델 재훈련**: `python retrain_model.py` (강제 재훈련)
- **기존 데이터 일괄 업데이트**: `python batch_update_ai.py` (기존 일기에 새로운 AI 분석 적용)
- **코멘트 검증**: `python verify_comments.py`

## 📁 프로젝트 구조

- `ai_analysis.py`: 핵심 AI 로직 (훈련, 추론, 지속성 관리).
- `app.py`: Flask REST API 라우트.
- `models.py`: SQLAlchemy 데이터베이스 모델 (`User`, `Diary`, `EmotionKeyword`).
- `*.h5 / *.pickle`: 최적화된 AI 모델 파일.

## 🔄 최근 업데이트 (2026.01.15)

### 1. AI 모델 업그레이드 (Polyglot-Ko 1.3B)

- 기존 **KoGPT-2** (1.2억 파라미터)에서 **Polyglot-Ko 1.3B** (13억 파라미터)로 교체했습니다.
- **향상된 점**: 문맥 이해력 대폭 증가, 더 자연스럽고 풍부한 한국어 표현 가능.

### 2. 프롬프트 엔지니어링 강화 (Persona 적용)

- AI에게 **"다정하고 공감 능력이 뛰어난 심리 상담사"** 페르소나를 부여했습니다.
- 단순한 응답을 넘어, 사용자의 일기 내용에 깊이 공감하고 위로하는 2~3문장의 답변을 생성하도록 최적화되었습니다.

### 3. 클라우드 배포 최적화 (Oracle Cloud)

- **메모리 최적화**: 대형 언어 모델(LLM) 구동을 위한 메모리 관리 로직 적용.
- **안전성**: `SKIP_TRAINING=true` 환경에서도 필수 AI 데이터(감정 은행 등)는 로딩되도록 수정.
- **타임아웃 설정**: LLM 추론 시간을 고려하여 Gunicorn 타임아웃을 **120초**로 확장.

### 4. 로컬 AI 성능 최적화 (2026.01.17 ~ 2026.01.18)

- **로컬 LLM 통합 분석 (Gemma 2)**:
- 기존 로컬 LSTM 분석과 함께 **Gemma 2 (2B)**를 이용한 통합 분석(감정 분류 + 코멘트 생성)을 도입했습니다.
- **성능 향상**: 외부 API 호출 없이 로컬 자원만으로 빠르고 안전하게 분석합니다.
- **로컬 최적화**: 메모리 효율성을 위해 모델을 게으른 로딩(Lazy Loading) 방식으로 관리합니다.
- **데이터 기반 통계 리포트 (Insight v2)**:
  - **AI 우선 감정 시스템**: 통계 차트에서 사용자 선택보다 AI가 객관적으로 분석한 감정 점수를 최우선으로 반영하여 더 정교한 분석 리포트를 제공합니다.
  - **KST 타임존 보정**: 서버 시간(UTC)과 상관없이 한국 표준시(+9시간) 기준으로 정확한 날짜별 통계를 산출합니다.
- **히스토리 패턴 기반 날씨 조언**:
  - 단순히 현재 날씨만 언급하는 것이 아니라, 사용자의 **과거 데이터(동일 날씨에서의 감정 패턴)**를 분석하여 "지난번 흐린 날에는 이런 감정을 느끼셨는데, 오늘은 어떠세요?"와 같은 초개인화된 인사이트를 제공합니다.
- **프라이버시 실드(Privacy Shield)**:
  - 외부 API 전송 전 이메일, 전화번호 등 민감 정보를 자동으로 마스킹하고, 최소한의 맥락 정보만 추출하여 보안을 강화했습니다.
- **설정 및 실행**:
  - **설정 및 실행**:
  - `Ollama` 서버가 실행 중이어야 합니다 (`ollama serve`).
  - 추천 실행 방식 (OCI): `nohup ./venv/bin/python app.py > app.log 2>&1 &`

### 5. 로컬 AI & OCI 성능 최적화 (2026.01.18)

- **로컬 LLM 도입 (Gemma 2 - 2B)**:
  - 구글의 최신 경량화 모델인 **Gemma 2 (2B)**를 로컬 서버(Ollama)에 탑재했습니다.
  - **장점**: 외부 API 의존성 완전 제거, 데이터 프라이버시 100% 보장.
  - **비용**: 구글 API 과금 및 Quota 제한 없이 **평생 무료/무제한** 사용 가능.
  - **속도**: 9B 모델 대비 4배 빠른 추론 속도 (OCI ARM 서버 기준 1분 내외).

- **배치 처리 시스템 (Resumable Batch)**:
  - 대량의 일기 데이터를 안정적으로 분석하기 위한 **'이어하기(Rescue)'** 기능 구현.
  - 서버 중단/재시작 시에도 이미 분석된 데이터는 건너뛰고 남은 데이터만 효율적으로 처리.
  - **작동 방식**: 백그라운드(`nohup`)에서 실행하며, 처리된 항목은 `task_id`로 추적.

- **설정 및 실행**:
  - **필수**: 서버에 `Ollama` 설치 및 `ollama pull gemma2:2b` 필요.
  - **실행**: `./venv/bin/python batch_gemini_update.py` (배치 모드)
  - **운영**: API 키 불필요, 오직 서버의 로컬 컴퓨팅 파워만 사용.

## 최근 작업 상황 및 업데이트 내역 (2026-01-19 기준)

### 1. AI 심층 리포트 생성 최적화 (504 Gateway Timeout 해결)

- **문제 해결**: AI 리포트 생성 시 발생하는 긴 대기 시간으로 인한 `504 Gateway Timeout` 오류 해결.
- **비동기 처리 도입**:
  - **Backend**: 리포트 생성 요청을 백그라운드 스레드에서 처리하고 즉시 응답 반환.
  - **Frontend**: 생성 요청 후 `completed` 상태가 될 때까지 주기적으로(3초) 상태를 폴링(Polling)하는 방식으로 변경.
  - **UI 개선**: 리포트 생성 중 "로딩 화면"을 표시하고, 생성 완료 시 결과 리포트를 렌더링하도록 `StatsPage.vue` 업데이트.

### 2. OCI 서버 배포 및 환경 설정

- **배포 완료**: Oracle Cloud Infrastructure (OCI) 인스턴스에 성공적으로 배포.
- **Nginx 설정**:
  - Reverse Proxy 설정을 통해 포트 80 접속을 백엔드/프론트엔드로 라우팅.
  - `Access-Control-Allow-Origin` 등 CORS 헤더를 Nginx 레벨에서 처리하여 API 통신 문제 해결.
- **Python 환경**: 가상 환경 설정 및 패키지 의존성 문제(TensorFlow, Dotenv 등) 해결.

### 3. AI 모델 및 데이터 고도화

- **이미지 분류**: `MobileNetV2` 기반의 미세 조정(Fine-tuning) 모델을 적용하여 분류 정확도 향상.
- **감정 분석**:
  - `GoEmotions-Korean` 데이터셋을 활용하여 28가지 세부 감정을 5대 핵심 감정으로 매핑.
  - 로컬 LLM (`Gemma 2`)을 활용한 심층 분석 및 문맥 인식 코멘트 생성 (`ai_brain.py`).

### 4. 프론트엔드 및 데이터 개선

- **Emoji 개선**: 기존 텍스트 이모지를 고화질 PNG 이미지로 전면 교체하여 시각적 품질 향상 (`EmojiSelector`, `CalendarGrid`).
- **데이터셋 구축**: 테스트 및 학습을 위한 대량의 다이어리 데이터(10,000건+) 생성 및 DB 적재 완료.

### 6. 보이스 다이어리 및 AI 성능 최적화 (2026.01.21)

- **보이스 다이어리 (Voice Diary) 기능 추가**:
  - **음성 인식 (STT)**: `faster-whisper` 모델을 탑재하여 빠르고 정확한 음성-텍스트 변환 구현.
  - **항목별 녹음**: 사용자가 질문별(사건, 감정, 의미, 위로)로 나누어 녹음할 수 있도록 UI/UX 개선.
  - **효율성**: 별도의 외부 API 없이 로컬 서버 자원(CPU)만을 활용하여 운영 비용 절감.

- **AI 분석 엔진 경량화 및 최적화**:
  - **모델 다이어트**: 메모리 사용량이 높은 `Polyglot-Ko` 모델을 **완전히 제거**하고, 경량화된 `Gemma 2 (2B)` 모델과 키워드/라벨링 시스템으로 일원화했습니다.
  - **자원 재사용 (Singleton)**: 분석 도구(`EmotionAnalysis`)를 매번 새로 생성하는 대신, 전역 인스턴스로 관리하여 반복적인 로딩 오버헤드를 제거했습니다.
  - **속도 개선 (Threading)**: 일기 저장 시 Redis/Celery와 같은 무거운 메시지 큐 시스템 대신 Python 내장 `Threading`을 사용하여 **저장 속도를 획기적으로 개선(즉시 저장)**했습니다.

- **서버 안정성 확보**:
  - **게으른 로딩 (Lazy Loading)**: AI 모델을 서버 시작 시점이 아닌 **실제 사용 시점**에 로드하도록 변경하여 초기 부팅 속도를 높이고 불필요한 메모리 점유를 막았습니다.

---

## 💎 '마음온' 온디바이스 AI 고도화 (2026.01.23)

### 1. 전용 LLM 파인튜닝 (Gemma 2 - 2B)

- **상담사 페르소나 구축**: 사용자의 감정에 깊이 공감하고 다뜻한 위로를 건네는 **'마음온' 전용 모델**을 학습시켰습니다.
- **데이터 증강 (Data Augmentation)**: 기존 1.2만 건의 데이터셋을 GPT-4o를 활용해 고품질 공감 답변으로 업그레이드하여 학습에 사용했습니다.
- **학습 결과**: MLX LoRA 방식을 사용하여 최종 손실값(Loss) **0.654**를 달성, 매우 안정적이고 감성적인 답변 성능을 확보했습니다.

### 2. 모바일 최적화 (4-bit Quantization)

- **경량화**: 4.9GB의 거대한 모델을 **4비트 양자화(4-bit Quantization)** 기술을 통해 **1.4GB**로 압축했습니다.
- **성능**: 모델 크기는 줄었으나 답변의 품질은 유지되며, 아이폰의 제한된 RAM 환경에서도 튕기지 않고 부드럽게 돌아가도록 최적화되었습니다.

### 3. iOS 온디바이스 AI 통합 완료

- **완전 로컬 추론**: 인터넷 연결이나 외부 서버 호출 없이 사용자의 아이폰 내부(GPU/Neural Engine)에서 AI가 직접 동작합니다.
- **프라이버시 강화**: 민감한 일기 내용이 외부로 전송될 필요가 전혀 없어, 보안성이 월등히 향상되었습니다.
- **실시간 스트리밍**: MLX-Swift-LM 라이브러리를 통해 AI의 답변이 한 글자씩 실시간으로 출력되는 스트리밍 기능을 구현했습니다.

### 7. 채팅 UI/UX 고도화 및 접근 제어 실현 (2026.01.26)

- **프리미엄 UI/UX 전면 적용**:
  - **커스텀 모달 도입**: 투박한 시스템 알림창(`alert`, `confirm`)을 앱 디자인과 통합된 **전용 모달(Reset, Exit, Restore)**로 전면 교체하여 몰입감을 높였습니다.
  - **대화 복구 시스템**: 사용자가 실수로 채팅창을 닫거나 이탈해도, 작성 중이던 내용을 자동으로 임시 저장하고 재방문 시 **"이어하기"**를 제안합니다.
  - **AI Thinking 시각화**: AI가 답변을 생성하는 동안 단순한 텍스트 대신 **풀스크린 프로세싱 모달**을 띄워, 전문적인 분석이 진행 중임을 시각적으로 전달합니다.

- **사용자 등급 기반 접근 제어 (RBAC)**:
  - **차별화된 경험 설계**: 사용자 위험도(`risk_level`)에 따라 '경증(Mild)' 사용자와 '중증/유료(Severe)' 사용자의 접근 권한을 철저히 분리했습니다.
  - **접근 제한 가드**: 경증 사용자가 전문 기능(심층 통계, 약물 관리 등)에 접근 시, 유료/전문 기능임을 안내하는 **'접근 제한 모달'**이 자동으로 작동합니다.

- **시스템 안정성 강화**:
  - **토큰 관리**: 로그인/로그아웃 시 구형 토큰 데이터를 확실하게 정리하여 권한 충돌 문제를 예방했습니다.
  - **호환성 패치**: CSS `appearance` 속성 등을 보강하여 다양한 모바일 브라우저에서도 UI가 깨지지 않도록 수정했습니다.

### 8. 위험 감지 및 실시간 심층 상담 기능 구현 (2026.01.26)

- **지능형 위험 감지 (Smart Triage)**:
  - **백엔드 (`ai_brain.py`)**: AI가 일기 내용을 분석할 때 단순히 감정만 파악하는 것이 아니라, 사용자의 `risk_level`과 일기 내용의 심각성을 종합적으로 판단합니다.
  - **위험 분류**: 일기 내용이 지나치게 짧거나 부정적 표현(예: "죽고 싶다", "무기력하다")이 감지되면 `NeedFollowup: YES` 플래그를 활성화합니다.
  - **맞춤형 질문 생성**: 상황에 맞는 추가 질문을 AI가 직접 생성합니다. (경증: "오늘 무슨 일이 있었나요?", 중증: "위험한 생각이 드셨나요?")

- **실시간 심층 상담 (Deep-Dive Chat)**:
  - **자동 전환**: 일기를 저장하자마자 AI가 추가 질문이 필요하다고 판단하면, 완료 화면 대신 **즉시 챗봇 상담 화면으로 전환**됩니다.
  - **문맥 유지**: 챗봇은 AI가 생성한 질문을 첫 마디로 대화를 시작하여, 끊김 없는 상담 경험을 제공합니다.
  - **데이터 통합**: 이 과정에서 나눈 대화 기록은 일기 데이터와 연동되어 추후 더 정밀한 분석 리포트에 활용됩니다.

- **데이터베이스 확장**:
  - `diaries` 컬렉션에 `followup_required (Boolean)` 및 `followup_question (Encrypted)` 필드를 추가하여 분석 상태를 체계적으로 관리합니다.

### 9. B2G 하이브리드 연동 및 iOS 디자인 안정화 (2026.01.27)

- **하이브리드 데이터 동기화 (B2G Sync)**:
  - **프라이버시 중심 설계**: 평소에는 외부 서버와 단절된 **온디바이스(On-Device) 로컬 모드**로 작동하며, 모든 임상 데이터는 사용자 기기에만 암호화되어 저장됩니다.
  - **선택적 공유 (Opt-in Sharing)**: 사용자가 보건소/상담센터에서 발급받은 **'기관 연동 코드'**를 입력할 때만, 핵심 임상 지표(위험도, 감정 그래프)를 선별하여 암호화된 채널로 전송하는 하이브리드 동기화 시스템을 구축했습니다.
  - **검증 시뮬레이터**: 네트워크가 없는 환경에서도 연동 로직을 검증할 수 있도록 `B2GManager` 내에 가상의 서버 응답 시뮬레이터를 내장했습니다.

- **iOS 디자인 시스템 안정화**:
  - **풀스크린 화면 대응**: 최신 아이폰의 노치(Notch) 및 다이내믹 아일랜드 디자인에 대응하여, 상하단 레터박스(검은 여백) 없이 화면을 꽉 채우도록 `LaunchScreen` 및 `Info.plist` 설정을 정밀 보정했습니다.
  - **XcodeGen 마이그레이션**: 복잡한 빌드 설정과 팀 인증 정보(Signing)를 코드 기반(`project.yml`)으로 완전 자동화하여, 협업 시 발생할 수 있는 설정 충돌 문제를 원천 차단했습니다.

- **개발자 도구 (Data Seeder)**:
  - **자동 더미 데이터 생성**: 시연 및 테스트 효율성을 위해, 버전 정보를 5회 터치하거나 개발자 메뉴를 통해 **'지난 2주간의 가상 감정 일기'**를 즉시 생성하는 `DataSeeder` 모듈을 탑재했습니다.
  - **현실성 강화**: 단순 난수가 아닌, 시간 흐름에 따른 감정 변 화와 그럴듯한 일기 내용을 포함하여 실제 사용 패턴과 유사한 데이터를 생성합니다.

### 10. iOS 앱 안정성 및 지능형 대화 최적화 (2026.01.28 ~ 2026.01.29)

- **백엔드 연동 완전 해결 (Connection Fix)**:
  - **404 및 연결 오류 수정**: Flask 백엔드의 정확한 포트(`5001`)와 URL 규칙(Trailing Slash 제거)을 `APIService`에 반영하여, 로그인 및 데이터 동기화 실패 문제를 완벽하게 해결했습니다.
  - **네트워크 안정성**: IP 변경 및 포트 충돌 상황에서도 안정적으로 백엔드에 접속하도록 설정을 최적화했습니다.

- **온디바이스 AI 메모리 최적화 (Anti-OOM)**:
  - **Dynamic Context Window**: 아이폰의 제한된 RAM을 고려하여, 대화 내역(`History`)을 무조건 쌓지 않고 상황에 따라 유동적으로 조절하는 스마트 로직을 도입했습니다.
  - **Smart Token Allocation**: 사용자의 질문 길이에 따라 답변 길이를 120~256 토큰 사이로 자동 조절하여, 불필요한 메모리 낭비를 줄이고 앱 크래시(OOM)를 원천 차단했습니다.
  - **System Prompt Diet**: 시스템 프롬프트를 핵심 규칙 4가지로 압축하여 문맥 윈도우 효율을 30% 이상 개선했습니다.

- **지능형 위기 감지 및 맥락 관리**:
  - **SOS 위기 대응 시스템**: 채팅 중 "죽고 싶다", "보건소" 등 위험 키워드가 감지되면, 즉시 **[긴급 도움 배너]**를 띄워 자살 예방 상담전화(1393) 등으로 연결하는 안전 장치를 마련했습니다.
  - **스마트 기억 소거 (Amnesia Control)**: 사용자가 "그만해", "똑같은 말 하네" 등 AI의 반복 발화에 불만을 표출할 때만 과거 기억을 지워(Reset) 루프를 탈출하도록 설계했습니다. (단, 긴 하소연 문장은 오탐지하지 않도록 길이 제한 적용)
