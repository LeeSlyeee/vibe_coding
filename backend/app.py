from flask import Flask, jsonify, request
from flask_cors import CORS
from flask_jwt_extended import JWTManager, create_access_token, jwt_required, get_jwt_identity
from flask_pymongo import PyMongo
from datetime import datetime, timedelta
from bson.objectid import ObjectId
import os
from config import Config
from config import Config
# Imports moved down to prevent circular dependency
# from tasks import process_diary_ai, analyze_diary_logic
# from ai_brain import EmotionAnalysis

app = Flask(__name__)
app.config.from_object(Config)

# Imports moved to bottom to prevent circular dependency hanging the route registration
# from tasks import process_diary_ai, analyze_diary_logic
# from ai_brain import EmotionAnalysis
# ...

# Global AI for immediate insights (Lazy loaded) - Kept for other routes
insight_ai = None

@app.route('/api/test/hello', methods=['GET'])
def test_hello():
    return jsonify({"message": "Hello from backend!"}), 200

@app.route('/api/chat/reaction', methods=['POST'])
@jwt_required()
def chat_reaction():
    # Use Standalone Function for robustness & Analysis capability
    data = request.json
    text = data.get('text', '')
    mode = data.get('mode', 'reaction') # Accept 'mode'
    if not text:
        return jsonify({'reaction': ""}), 200
        
    # Directly call function, bypassing class instantiation issues
    reaction = generate_analysis_reaction_standalone(text, mode=mode)
    return jsonify({'reaction': reaction}), 200

# ... (Previous code)

@app.route('/api/insight', methods=['GET'])
@jwt_required()
def get_insight():
    global insight_ai
    current_user_id = get_jwt_identity()
    
    # 1. Lazy Load AI
    if insight_ai is None:
        print("ğŸ’¡ Initializing AI for Insight (Lazy Load)...")
        try:
            insight_ai = EmotionAnalysis()
        except Exception as e:
            print(f"Failed to load AI: {e}")
            return jsonify({'message': "AIë¥¼ ì¤€ë¹„í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}), 503

    # 2. Date Calculation (Target Date - 3 Weeks)
    target_date_str = request.args.get('date')
    
    if target_date_str:
        try:
            # Parse 'YYYY-MM-DD' and set time to end of that day for inclusion
            target_date = datetime.strptime(target_date_str, '%Y-%m-%d')
            # End of target date (next day 00:00:00)
            end_date = target_date + timedelta(days=1)
        except ValueError:
            target_date = datetime.utcnow()
            end_date = target_date + timedelta(days=1)
    else:
        target_date = datetime.utcnow()
        end_date = target_date + timedelta(days=1)

    start_date = target_date - timedelta(weeks=1)
    
    try:
        # 3. Fetch Diaries (Range: Start -> End)
        print(f"ğŸ” [Insight] Query Range: {start_date} to {end_date} (User: {current_user_id})")
        cursor = mongo.db.diaries.find({
            'user_id': current_user_id,
            'created_at': {
                '$gte': start_date,
                '$lt': end_date
            }
        }).sort('created_at', 1) 
        
        recent_diaries = []
        for doc in cursor:
            recent_diaries.append({
                'date': doc.get('created_at').strftime('%Y-%m-%d') if doc.get('created_at') else '',
                'mood': doc.get('mood_level', 'ë³´í†µ'),
                'event': doc.get('event', '')[:50]
            })
        
        print(f"ğŸ“Š [Insight] Found {len(recent_diaries)} diaries for context.")

        # 3.5. Fetch Weather Stats (Historical Pattern)
        weather = request.args.get('weather')
        weather_stats = None
        if weather:
            print(f"ğŸ“Š [Insight] Finding historical patterns for weather: {weather}")
            # Search all past diaries with the same weather
            weather_cursor = mongo.db.diaries.find({
                'user_id': current_user_id,
                'weather': weather
            })
            
            emotion_counts = {}
            for doc in weather_cursor:
                # Use ai_prediction if available, else mood_level
                pred_raw = doc.get('ai_prediction', '')
                pred = pred_raw.split(' ')[0] if pred_raw else ""
                
                if not pred:
                    lvl = doc.get('mood_level', 3)
                    pred = {1:'í™”ë‚¨', 2:'ìš°ìš¸', 3:'í‰ë²”', 4:'í¸ì•ˆ', 5:'í–‰ë³µ'}.get(lvl, 'í‰ë²”')
                
                emotion_counts[pred] = emotion_counts.get(pred, 0) + 1
            
            if emotion_counts:
                # Sort by count
                sorted_emotions = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)
                # Keep top 2
                weather_stats = ", ".join([f"'{e[0]}'" for e in sorted_emotions[:2]])
                print(f"ğŸ“ˆ [Insight] Top emotions for {weather}: {weather_stats}")

        # 4. Generate Insight
        message = insight_ai.generate_pre_write_insight(recent_diaries, weather=weather, weather_stats=weather_stats)
        
        # If message is None (filtered or failed), return empty
        if not message:
             print("ğŸ’¡ [Insight] Final result is None (Fallback triggered)")
             return jsonify({'message': ""}), 200
             
        print(f"âœ… [Insight] Final Response: {message[:30]}...")
        return jsonify({'message': message}), 200
        
    except Exception as e:
        print(f"Insight Route Error: {e}")
        return jsonify({'message': ""}), 200

# ... (Existing Stats Route)


# MongoDB Setup
mongo = PyMongo(app)

# Check DB Connection
# try:
#     # Trigger a connection to verify
#     mongo.cx.server_info()
#     print("âœ… MongoDB Connected via PyMongo")
# except Exception as e:
#     print(f"âŒ MongoDB Connection Failed: {e}")

# CORS Setup
# CORS Setup
# CORS Setup - Allow All (Debug Mode)
# CORS(app, resources={
#     r"/*": {
#         "origins": "*",
#         "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
#         "allow_headers": ["Content-Type", "Authorization"],
#     }
# })

jwt = JWTManager(app)

# --- Helper Function for ObjectId Serialization ---
def serialize_doc(doc):
    if not doc:
        return None
    doc['id'] = str(doc['_id'])
    
    # Datetime Serialization
    if 'created_at' in doc and isinstance(doc['created_at'], datetime):
        doc['created_at'] = doc['created_at'].isoformat()
        
    if '_id' in doc:
        del doc['_id']
    return doc

# -------------------- Auth Routes --------------------

@app.route('/api/register', methods=['POST'])
def register():
    data = request.get_json()
    username = data.get('username')
    password = data.get('password')

    if mongo.db.users.find_one({'username': username}):
        return jsonify({"message": "User already exists"}), 400

    from werkzeug.security import generate_password_hash
    hashed_password = generate_password_hash(password, method='pbkdf2:sha256')

    user_id = mongo.db.users.insert_one({
        'username': username,
        'password_hash': hashed_password,
        'created_at': datetime.utcnow()
    }).inserted_id

    return jsonify({"message": "User registered successfully", "user_id": str(user_id)}), 201

@app.route('/api/login', methods=['POST'])
def login():
    data = request.get_json()
    username = data.get('username')
    password = data.get('password')

    user = mongo.db.users.find_one({'username': username})
    
    if not user:
         return jsonify({"message": "Invalid credentials"}), 401

    from werkzeug.security import check_password_hash
    if check_password_hash(user['password_hash'], password):
        # Use ObjectId string as identity
        access_token = create_access_token(identity=str(user['_id'])) 
        return jsonify(access_token=access_token, username=user['username']), 200

    return jsonify({"message": "Invalid credentials"}), 401

# -------------------- Diary Routes --------------------

from crypto_utils import crypto_manager

# ... imports ...

# Helper to Decrypt Doc
def decrypt_doc(doc):
    if not doc: return None
    sensitive_fields = ['event', 'emotion_desc', 'emotion_meaning', 'self_talk', 'sleep_condition', 'sleep_desc', 'ai_prediction', 'ai_comment', 'mindset']
    for field in sensitive_fields:
        if field in doc and isinstance(doc[field], str):
            doc[field] = crypto_manager.decrypt(doc[field])
    return doc

def map_ai_to_mood(ai_text):
    """
    Parses 'í‰ë²” (85%)' or 'í‰ë²”' style strings and maps them to 1-5 level.
    """
    if not ai_text: return None
    # 5: í–‰ë³µ, ê¸°ì¨
    if "í–‰ë³µ" in ai_text or "ê¸°ì¨" in ai_text: return 5
    # 4: í¸ì•ˆ, í‰ì˜¨
    if "í‰ì˜¨" in ai_text or "í¸ì•ˆ" in ai_text: return 4
    # 3: í‰ë²”, ì¤‘ë¦½, ë³´í†µ
    if "í‰ë²”" in ai_text or "ì¤‘ë¦½" in ai_text or "ë³´í†µ" in ai_text: return 3
    # 2: ìš°ìš¸, ìŠ¬í””, ë¹„í†µ
    if "ìš°ìš¸" in ai_text or "ìŠ¬í””" in ai_text: return 2
    # 1: í™”ë‚¨, ë¶„ë…¸
    if "í™”ë‚¨" in ai_text or "ë¶„ë…¸" in ai_text: return 1
    
    return None # Fallback to user_mood logic in caller

# Helper to Encrypt Data (for saving)
def encrypt_data(data):
    encrypted = {}
    sensitive_fields = ['event', 'emotion_desc', 'emotion_meaning', 'self_talk', 'sleep_condition', 'sleep_desc', 'ai_prediction', 'ai_comment', 'mindset']
    for k, v in data.items():
        if k in sensitive_fields and isinstance(v, str):
            encrypted[k] = crypto_manager.encrypt(v)
        else:
            encrypted[k] = v
    return encrypted

# --- Usage in Routes ---

@app.route('/api/diaries', methods=['GET'])
@jwt_required()
def get_diaries():
    current_user_id = get_jwt_identity()
    year = request.args.get('year', type=int)
    month = request.args.get('month', type=int)
    
    filter_query = {'user_id': current_user_id}
    if year and month:
        start_date = datetime(year, month, 1)
        if month == 12: end_date = datetime(year + 1, 1, 1)
        else: end_date = datetime(year, month + 1, 1)
        filter_query['created_at'] = {'$gte': start_date, '$lt': end_date}
    
    cursor = mongo.db.diaries.find(filter_query).sort('created_at', -1)
    if not (year and month): cursor = cursor.limit(100)
        
    # Decrypt each doc
    diaries = [serialize_doc(decrypt_doc(doc)) for doc in cursor]
    return jsonify(diaries), 200

@app.route('/api/diaries', methods=['POST'])
@jwt_required()
def create_diary():
    current_user_id = get_jwt_identity()
    data = request.get_json()
    print(f"ğŸ” [DEBUG] Received diary data: {data}")
    print(f"ğŸ” [DEBUG] sleep_desc value: '{data.get('sleep_desc', 'NOT_FOUND')}'")
    created_at_str = data.get('created_at')
    if created_at_str and created_at_str.endswith('Z'): created_at_str = created_at_str[:-1]
    created_at = datetime.fromisoformat(created_at_str) if created_at_str else datetime.utcnow()

    # Prepare raw data
    raw_diary = {
        'user_id': current_user_id,
        'event': data.get('event', ''),
        'sleep_desc': data.get('sleep_desc', ''),
        'emotion_desc': data.get('emotion_desc', ''),
        'emotion_meaning': data.get('emotion_meaning', ''),
        'self_talk': data.get('self_talk', ''),
        'mood_level': data.get('mood_level', 3),
        'weather': data.get('weather'),
        'temperature': data.get('temperature'),
        'ai_prediction': "ë¶„ì„ ì¤‘... (AIê°€ ê³§ ë‹µë³€í•´ë“œë ¤ìš”!)",
        'ai_comment': "ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”... ğŸ¤–",
        'created_at': created_at
    }
    
    # Encrypt before insert
    encrypted_diary = encrypt_data(raw_diary)
    
    try:
        result = mongo.db.diaries.insert_one(encrypted_diary)
        new_diary_id = str(result.inserted_id)
        
        # Trigger Task (Threading) only if AI analysis is missing
        request_ai_pred = data.get('ai_prediction', '').strip()
        request_ai_comment = data.get('ai_comment', '').strip()
        
        # Check if client provided valid analysis (Hybrid Logic)
        # Note: "ë¶„ì„ ì¤‘..." or similar placeholders mean no analysis provided.
        is_client_analyzed = (
            request_ai_pred and 
            request_ai_comment and 
            "ë¶„ì„ ì¤‘" not in request_ai_pred and 
            "ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”" not in request_ai_comment
        )

        task_id = "local-thread"
        
        if is_client_analyzed:
            print("ğŸ“± [Hybrid] Client provided AI analysis. Back-end analysis skipped.")
            task_id = "client-side"
            # Update the stored document with the provided AI fields if raw_diary had placeholders
            # But wait, raw_diary was initialized with placeholders above. 
            # We need to update raw_diary BEFORE encryption or update the DB after.
            # Let's adjust raw_diary creation.
            
            # Actually, raw_diary logic above set default placeholders. 
            # We should used the provided values if they exist.
            # Let's correct the workflow:
            # 1. We already inserted the doc. If we want to use client values, we should have used them in insert.
            # To fix this without massive refactor: We update the doc immediately if client provided data.
            
            # Re-encrypt client provided values
            ai_updates = {
                'ai_prediction': crypto_manager.encrypt(request_ai_pred),
                'ai_comment': crypto_manager.encrypt(request_ai_comment),
                'task_id': 'client-side'
            }
            mongo.db.diaries.update_one({'_id': result.inserted_id}, {'$set': ai_updates})
            
            # Update response data to reflect this
            raw_diary['ai_prediction'] = request_ai_pred
            raw_diary['ai_comment'] = request_ai_comment
            
        else:
            print("â˜ï¸ [Hybrid] No AI analysis provided. Triggering Server AI...")
            try:
                threading.Thread(
                    target=analyze_diary_logic, 
                    args=(new_diary_id,)
                ).start()
                mongo.db.diaries.update_one({'_id': result.inserted_id}, {'$set': {'task_id': task_id}})
            except Exception as e:
                print(f"Failed to start thread: {e}")
        
        # Return Decrypted Response
        raw_diary['_id'] = result.inserted_id
        response_data = serialize_doc(raw_diary)
        response_data['task_id'] = task_id
        return jsonify(response_data), 201
        
    except Exception as e:
        return jsonify({"message": f"Create failed: {str(e)}"}), 500

@app.route('/api/diaries/<id>', methods=['GET'])
@jwt_required()
def get_diary(id):
    current_user_id = get_jwt_identity()
    if not ObjectId.is_valid(id): return jsonify({"message": "Invalid ID"}), 400
    
    diary = mongo.db.diaries.find_one({'_id': ObjectId(id)})
    if not diary: return jsonify({"message": "Not found"}), 404
    if diary.get('user_id') != current_user_id: return jsonify({"message": "Unauthorized"}), 403
    
    return jsonify(serialize_doc(decrypt_doc(diary))), 200

@app.route('/api/diaries/<id>', methods=['PUT'])
@jwt_required()
def update_diary(id):
    current_user_id = get_jwt_identity()
    if not ObjectId.is_valid(id): return jsonify({"message": "Invalid ID"}), 400
    
    diary = mongo.db.diaries.find_one({'_id': ObjectId(id)})
    if not diary: return jsonify({"message": "Not found"}), 404
    if diary.get('user_id') != current_user_id: return jsonify({"message": "Unauthorized"}), 403
    
    data = request.get_json()
    
    # Prepare update fields
    updates = {
        'event': data.get('event', crypto_manager.decrypt(diary.get('event'))), # Use existing decrypted if not provided
        'sleep_desc': data.get('sleep_desc', crypto_manager.decrypt(diary.get('sleep_desc'))),
        'emotion_desc': data.get('emotion_desc', crypto_manager.decrypt(diary.get('emotion_desc'))),
        'emotion_meaning': data.get('emotion_meaning', crypto_manager.decrypt(diary.get('emotion_meaning'))),
        'self_talk': data.get('self_talk', crypto_manager.decrypt(diary.get('self_talk'))),
        'mood_level': data.get('mood_level', diary.get('mood_level')),
        'weather': data.get('weather', diary.get('weather')),
        'temperature': data.get('temperature', diary.get('temperature')),
        'ai_prediction': "ì¬ë¶„ì„ ì¤‘...",
        'ai_comment': "AIê°€ ë‹¤ì‹œ ìƒê°í•˜ê³  ìˆì–´ìš”... ğŸ¤”"
    }
    
    # Encrypt updates
    encrypted_updates = encrypt_data(updates)
    
    mongo.db.diaries.update_one({'_id': ObjectId(id)}, {'$set': encrypted_updates})
    
    mongo.db.diaries.update_one({'_id': ObjectId(id)}, {'$set': encrypted_updates})
    
    # [Hybrid Logic for Update]
    # Check if client provided valid analysis in this update request
    req_ai_pred = data.get('ai_prediction', '').strip()
    req_ai_comment = data.get('ai_comment', '').strip()
    
    is_client_analyzed = (
        req_ai_pred and 
        req_ai_comment and 
        "ì¬ë¶„ì„ ì¤‘" not in req_ai_pred and 
        "ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”" not in req_ai_comment
    )

    if is_client_analyzed:
        print(f"ğŸ“± [Hybrid-Update] Client provided AI analysis for {id}. Server analysis skipped.")
        # We don't need to do anything extra because we already saved the encrypted_updates above,
        # which included ai_prediction/ai_comment if they were present in 'data'.
        # Wait, let's double check 'encrypted_updates' creation above.
        
        # 'updates' dict above sets ai_prediction to "ì¬ë¶„ì„ ì¤‘..." by default.
        # We need to override that default if client provided data.
        
        # Correct logic:
        # If client provided data, we should have used it in 'updates' dict.
        # Since 'updates' dict was hardcoded with placeholders, we must update DB again here.
        
        ai_fix = {
            'ai_prediction': crypto_manager.encrypt(req_ai_pred),
            'ai_comment': crypto_manager.encrypt(req_ai_comment),
            'task_id': 'client-side-update'
        }
        mongo.db.diaries.update_one({'_id': ObjectId(id)}, {'$set': ai_fix})
        
    else:
        print(f"â˜ï¸ [Hybrid-Update] No AI provided. Triggering Server AI Re-analysis for {id}...")
        try:
            threading.Thread(
                target=analyze_diary_logic,
                args=(id,)
            ).start()
            mongo.db.diaries.update_one({'_id': ObjectId(id)}, {'$set': {'task_id': 'local-thread'}})
        except Exception as e: 
            print(f"Failed to start thread: {e}")
    
    # Return decrypted
    updated_diary = mongo.db.diaries.find_one({'_id': ObjectId(id)})
    return jsonify(serialize_doc(decrypt_doc(updated_diary))), 200

@app.route('/api/diaries/<id>', methods=['DELETE'])
@jwt_required()
def delete_diary(id):
    current_user_id = get_jwt_identity()
    print(f"ğŸ—‘ï¸ [DELETE] Request for ID: {id}, User: {current_user_id}")
    
    if not ObjectId.is_valid(id): 
        print("âŒ Invalid ID format")
        return jsonify({"message": "Invalid ID"}), 400
    
    diary = mongo.db.diaries.find_one({'_id': ObjectId(id)})
    if not diary: 
        print("âŒ Diary not found in DB")
        return jsonify({"message": "Not found"}), 404
        
    print(f"ğŸ“„ Found Diary User: {diary.get('user_id')}")
    
    if diary.get('user_id') != current_user_id: 
        print("âŒ Unauthorized: User mismatch")
        return jsonify({"message": "Unauthorized"}), 403
    
    result = mongo.db.diaries.delete_one({'_id': ObjectId(id)})
    print(f"âœ… Delete Result: {result.deleted_count}")
    
    return jsonify({"message": "Deleted successfully"}), 200

@app.route('/api/diaries/search', methods=['GET'])
@jwt_required()
def search_diaries():
    current_user_id = get_jwt_identity()
    query = request.args.get('q', '')
    if not query: return jsonify([]), 200
    
    # âš ï¸ Encryption Limitation: Cannot use MongoDB $regex.
    # Must fetch ALL diaries (id, dates) and decrypt in memory to search.
    # For 20k diaries, this might be slow. Limit to last 1000 for performance?
    # Or fetch all. Let's try last 500 for responsiveness.
    
    cursor = mongo.db.diaries.find({'user_id': current_user_id}).sort('created_at', -1).limit(500)
    
    results = []
    for doc in cursor:
        decrypted = decrypt_doc(doc)
        # Search in decrypted fields
        if (query in decrypted.get('event','') or 
            query in decrypted.get('emotion_desc','') or 
            query in decrypted.get('emotion_meaning','') or 
            query in decrypted.get('self_talk','')):
            results.append(serialize_doc(decrypted))
            if len(results) >= 50: break # Limit output
            
    return jsonify(results), 200

@app.route('/api/weather-insight', methods=['GET'])
@jwt_required()
def weather_insight():
    # Similar adjustment needed if aggregation uses encrypted fields.
    # But weather insight logic currently uses 'mood_level' (int) and 'weather' (plain string probably?)
    # Weather field was NOT in sensitive list in migrate script. So it's plain text.
    # Aggregation works fine!
    return weather_insight_original() # Wrapper to keep original logic logic

# For Statistics, we need to decrypt AI prediction
@app.route('/api/statistics', methods=['GET'])
@jwt_required()
def get_statistics():
    user_id = get_jwt_identity()
    diaries = list(mongo.db.diaries.find({'user_id': user_id}).sort('created_at', 1))
    
    from datetime import timedelta
    KST = timedelta(hours=9)
    
    stats = {
        'monthly': {},
        'moods': {1: 0, 2: 0, 3: 0, 4: 0, 5: 0},
        'weather': {},
        'daily_sum': {},
        'daily_count': {},
        'timeline': []
    }
    
    for d in diaries:
        # Full Decryption
        decrypted = decrypt_doc(d)
        
        # Extract Data from Decrypted Doc
        ai_pred_raw = decrypted.get('ai_prediction')
        user_mood = decrypted.get('mood_level')
        weather = decrypted.get('weather')
        created_at = decrypted.get('created_at') # Should be datetime object from decrypt_doc logic

        # Determine Mood
        ai_mood = map_ai_to_mood(ai_pred_raw)
        mood = ai_mood if ai_mood else (user_mood if user_mood is not None else 3)
        
        try: 
            mood = int(mood)
        except: 
            mood = 3
        if not (1 <= mood <= 5): mood = 3
            
        if not created_at: continue
        
        # Handle timezone if naive or UTC
        # Assuming decrypt_doc returns datetime. If it's UTC, add KST.
        # If decrypt_doc handles timezone, adjust accordingly. 
        # Usually pymongo returns UTC datetime.
        local_date = created_at + KST
        date_str = local_date.strftime('%Y-%m-%d')
        month_str = local_date.strftime('%Y-%m')
        
        stats['monthly'][month_str] = stats['monthly'].get(month_str, 0) + 1
        stats['moods'][mood] = stats['moods'].get(mood, 0) + 1
        
        if weather:
            if weather not in stats['weather']: stats['weather'][weather] = {'1': 0, '2': 0, '3': 0, '4': 0, '5': 0, 'total': 0}
            stats['weather'][weather][str(mood)] += 1
            stats['weather'][weather]['total'] += 1
            
        stats['daily_sum'][date_str] = stats['daily_sum'].get(date_str, 0) + mood
        stats['daily_count'][date_str] = stats['daily_count'].get(date_str, 0) + 1
        
        stats['timeline'].append({
            'date': date_str,
            'mood_level': mood,
            'ai_label': ai_pred_raw if ai_pred_raw else '',
            'user_mood': user_mood
        })

    daily_moods = {}
    for k in stats['daily_sum']:
        daily_moods[k] = round(stats['daily_sum'][k] / stats['daily_count'][k])

    response_data = {
        'monthly': sorted([{'month': k, 'count': v} for k, v in stats['monthly'].items()], key=lambda x: x['month']),
        'moods': sorted([{'_id': k, 'count': v} for k, v in stats['moods'].items()], key=lambda x: x['_id']),
        'daily': sorted([{'_id': k, 'count': v} for k, v in daily_moods.items()], key=lambda x: x['_id']),
        'timeline': stats['timeline'],
        'weather': []
    }
    
    for w, counts in stats['weather'].items():
        moods_list = [{'mood': m, 'count': counts[str(m)]} for m in range(1, 6) if counts[str(m)] > 0]
        response_data['weather'].append({'_id': w, 'moods': moods_list, 'total_count': counts['total']})
    
    response_data['weather'].sort(key=lambda x: x['total_count'], reverse=True)
    return jsonify(response_data), 200

# Need to redefine weather_insight_original or just keep it as is since it wasn't modified in the diff block logic
def weather_insight_original():
    current_user_id = get_jwt_identity()
    weather_str = request.args.get('weather', '')
    date_str = request.args.get('date', '')
    if not weather_str: return jsonify({'message': 'ë‚ ì”¨ ì •ë³´ê°€ ì—†ì–´ìš”.'}), 200
    
    keywords = ["ë¹„", "ëˆˆ", "ë§‘ìŒ", "íë¦¼", "êµ¬ë¦„"]
    target_keyword = "ë§‘ìŒ"
    for k in keywords:
        if k in weather_str:
            target_keyword = k
            break
            
    pipeline = [
        {"$match": {"user_id": current_user_id, "weather": {"$regex": target_keyword}}},
        {"$group": {"_id": "$mood_level", "count": {"$sum": 1}}},
        {"$sort": {"count": -1}},
        {"$limit": 1}
    ]
    
    try:
        result = list(mongo.db.diaries.aggregate(pipeline))
        if not result: return jsonify({'message': f"{weather_str}, ê¸°ë¡ëœ íŒ¨í„´ì´ ì—†ë„¤ìš”."}), 200
        top_mood = result[0]['_id']
        mood_msg_map = {1: "ì˜ˆë¯¼", 2: "ìš°ìš¸", 3: "í‰ë²”", 4: "í‰ì˜¨", 5: "í–‰ë³µ"}
        mood_desc = mood_msg_map.get(top_mood, "ë‹¤ì–‘í•œ")
        return jsonify({'message': f"'{target_keyword}' ë‚ ì”¨ì—ëŠ” ì£¼ë¡œ {mood_desc}í•œ ê¸°ë¶„ì„ ëŠë¼ì…¨ì–´ìš”."}), 200
    except:
        return jsonify({'message': ""}), 200

# Async Report Generation
import threading

# Global AI Brain Instance for reuse (Singleton)
global_ai_brain = None

def get_ai_brain():
    global global_ai_brain
    if global_ai_brain is None:
        from ai_brain import EmotionAnalysis
        print("ğŸ§  [App] Initializing Global EmotionAnalysis Instance...")
        global_ai_brain = EmotionAnalysis()
    return global_ai_brain

def background_generate_task(app_instance, user_id, final_input):
    """Background thread to generate report without blocking"""
    with app_instance.app_context():
        try:
            print(f"ğŸ§µ [Thread] Starting background report generation for {user_id}")
            ai = get_ai_brain()
            report_content = ai.generate_comprehensive_report(final_input)
            
            # 1. Archive Report (New Collection)
            new_report = {
                'user_id': user_id,
                'content': report_content,
                'created_at': datetime.utcnow(),
                'type': 'comprehensive'
            }
            mongo.db.reports.insert_one(new_report)
            print(f"âœ… [Thread] Report archived to DB.")
            
            # 2. Update User Status
            mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$set': {
                    'report_status': 'completed',
                    'latest_report': report_content,
                    'report_updated_at': datetime.utcnow()
                }}
            )
            print(f"âœ… [Thread] Report generation complete for {user_id}")
            
        except Exception as e:
            print(f"âŒ [Thread] Report generation failed: {e}")
            mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$set': {'report_status': 'failed'}}
            )

def background_long_term_task(app_instance, user_id, history_data):
    """Background thread to generate long-term insight without blocking"""
    with app_instance.app_context():
        try:
            print(f"ğŸ§µ [Thread] Starting long-term analysis for {user_id}")
            ai = get_ai_brain()
            insight = ai.generate_long_term_insight(history_data)
            
            # Update User Status & Result
            mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$set': {
                    'longterm_status': 'completed',
                    'longterm_result': insight,
                    'longterm_updated_at': datetime.utcnow()
                }}
            )
            print(f"âœ… [Thread] Long-term analysis complete for {user_id}")
            
        except Exception as e:
            print(f"âŒ [Thread] Long-term analysis failed: {e}")
            mongo.db.users.update_one(
                {'_id': ObjectId(user_id)},
                {'$set': {'longterm_status': 'failed'}}
            )

@app.route('/api/report/longterm/start', methods=['POST'])
@jwt_required()
def start_long_term_report():
    user_id = get_jwt_identity()
    
    # 1. Fetch Past Reports (Limit 5 most recent)
    cursor = mongo.db.reports.find({'user_id': user_id, 'type': 'comprehensive'}).sort('created_at', -1).limit(5)
    reports = list(cursor)
    
    if len(reports) < 2:
        return jsonify({"message": "ì¥ê¸° ë¶„ì„ì„ í•˜ë ¤ë©´ ìµœì†Œ 2ê°œ ì´ìƒì˜ ì‹¬ì¸µ ë¦¬í¬íŠ¸ê°€ í•„ìš”í•´ìš”."}), 400
        
    # Prepare Data
    reports.reverse() 
    history_data = []
    for r in reports:
        history_data.append({
            'date': r['created_at'].strftime('%Y-%m-%d'),
            'content': r['content']
        })
        
    # 2. Set Status & Start Thread
    mongo.db.users.update_one(
        {'_id': ObjectId(user_id)},
        {'$set': {'longterm_status': 'processing'}}
    )

    thread = threading.Thread(target=background_long_term_task, args=(app, user_id, history_data))
    thread.start()
        
    return jsonify({"status": "processing", "message": "ê³¼ê±° ê¸°ë¡ í†µí•© ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤."}), 202

@app.route('/api/report/longterm/status', methods=['GET'])
@jwt_required()
def check_long_term_report_status():
    user_id = get_jwt_identity()
    user = mongo.db.users.find_one({'_id': ObjectId(user_id)})
    
    if not user:
        return jsonify({"status": "none"}), 200
        
    status = user.get('longterm_status', 'none')
    insight = ''
    
    if status == 'completed':
        insight = user.get('longterm_result', '')
        
    return jsonify({"status": status, "insight": insight}), 200

@app.route('/api/report/start', methods=['POST'])
@jwt_required()
def start_report_generation():
    user_id = get_jwt_identity()

    # 1. Check Diaries
    cursor = mongo.db.diaries.find({'user_id': user_id}).sort('created_at', -1).limit(50)
    diaries = list(cursor)

    if len(diaries) < 3:
        return jsonify({"status": "error", "message": "ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 3ì¼ ì´ìƒì˜ ê¸°ë¡ì´ í•„ìš”í•´ìš”."}), 400

    # 2. Summarize Data
    summary_lines = []
    mood_counts = {}

    for d in diaries:
        decrypted = decrypt_doc(d)
        date = decrypted.get('created_at').strftime('%Y-%m-%d') if decrypted.get('created_at') else "ë‚ ì§œì—†ìŒ"
        mood = decrypted.get('mood_level', 3)
        event = decrypted.get('event', '')[:50].replace('\n', ' ')
        emotion = decrypted.get('emotion_desc', '')[:30]
        thought = decrypted.get('emotion_meaning', '')[:30]
        
        summary_lines.append(f"- {date} (ê¸°ë¶„:{mood}/5): {event} | ê°ì •: {emotion} | ìƒê°: {thought}")
        mood_counts[mood] = mood_counts.get(mood, 0) + 1

    summary_text = "\n".join(summary_lines)
    stats_text = f"ìµœê·¼ {len(diaries)}ì¼ê°„ ê¸°ë¶„ ë¶„í¬: {mood_counts}"
    final_input = f"{stats_text}\n\n[ìµœê·¼ ì¼ê¸° ìš”ì•½]\n{summary_text}"

    # 3. Set Status & Start Thread
    mongo.db.users.update_one(
        {'_id': ObjectId(user_id)},
        {'$set': {'report_status': 'processing'}}
    )

    thread = threading.Thread(target=background_generate_task, args=(app, user_id, final_input))
    thread.start()

    return jsonify({"status": "processing", "message": "ë¦¬í¬íŠ¸ ë¶„ì„ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤."}), 202

@app.route('/api/report/status', methods=['GET'])
@jwt_required()
def check_report_status():
    user_id = get_jwt_identity()
    user = mongo.db.users.find_one({'_id': ObjectId(user_id)})
    
    if not user:
        return jsonify({"status": "none"}), 200
        
    status = user.get('report_status', 'none')
    report = ''
    
    if status == 'completed':
        report = user.get('latest_report', '')
        
    return jsonify({"status": status, "report": report}), 200

@app.route('/api/voice/transcribe', methods=['POST'])
@jwt_required()
def transcribe_voice():
    print(f"ğŸ¤ [DEBUG] Headers: {request.headers}")
    print(f"ğŸ¤ [DEBUG] Files: {request.files}")
    if 'file' not in request.files:
        print("âŒ [DEBUG] No 'file' key in request.files")
        return jsonify({"message": "No file part (DEBUG: file key missing)"}), 400
    
    file = request.files['file']
    print(f"ğŸ¤ [DEBUG] Filename: {file.filename}")
    if file.filename == '':
        print("âŒ [DEBUG] Empty filename")
        return jsonify({"message": "No selected file (DEBUG: filename empty)"}), 400
        
    if file:
        try:
            filename = secure_filename(file.filename)
            # Create temp file
            # Determine suffix based on filename or default to .webm
            suffix = os.path.splitext(filename)[1]
            if not suffix: suffix = ".webm"
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as temp:
                file.save(temp.name)
                temp_path = temp.name
                
            print(f"ğŸ™ï¸ Transcribing file: {temp_path}")
            text = voice_brain_instance.transcribe(temp_path)
            
            # Clean up
            os.remove(temp_path)
            
            # Check for auto-structure request
            auto_fill = request.form.get('auto_fill', 'false').lower() == 'true'
            
            response_data = {"text": text}
            
            if auto_fill and text and len(text) > 10:
                print(f"ğŸ§  Auto-Filling requested for: {text[:30]}...")
                structured_data = voice_brain_instance.structure_diary_text(text)
                if structured_data:
                    response_data['structured'] = structured_data
            
            return jsonify(response_data), 200
        except Exception as e:
            print(f"âŒ Transcribe Error: {e}")
            import traceback
            traceback.print_exc()
            return jsonify({"message": f"Transcription failed: {str(e)}"}), 500

if __name__ == '__main__':
    # No SQL create_all() needed
    app.run(debug=True, use_reloader=False, host='0.0.0.0', port=5001)
 

# Standalone Function Injected directly into app.py
def generate_analysis_reaction_standalone(user_text, mode='reaction'):
    print(f"DEBUG: generate_analysis_reaction_standalone (Local) called. Mode={mode}")
    if not user_text: return None
    import re
    import requests
    import random
    
    # 1. Sanitize
    text = re.sub(r'[\w\.-]+@[\w\.-]+', '[EMAIL]', user_text)
    sanitized = text[:300]
    
    # 2. Prompt Switching
    if mode == 'question':
        prompt_text = (
            f"ë‚´ë‹´ìì˜ ë§: \"{sanitized}\"\n\n"
            "ë‚´ë‹´ìê°€ ë„ˆë¬´ ì§§ê³  ë‹¨ë‹µí˜•ìœ¼ë¡œ ëŒ€ë‹µí–ˆì–´. ëŒ€í™”ë¥¼ ë” ê¹Šê²Œ ì´ëŒì–´ë‚´ê¸° ìœ„í•´ **ìì—°ìŠ¤ëŸ¬ìš´ ê¼¬ë¦¬ ì§ˆë¬¸**ì„ í•˜ë‚˜ ë˜ì ¸ì¤˜.\n"
            "ì§€ì‹œì‚¬í•­:\n"
            "1. ë‚´ë‹´ìì˜ ë§ì„ ë°˜ë³µí•˜ê¸°ë³´ë‹¤, ê·¸ ì´ë©´ì˜ ì´ìœ ë‚˜ êµ¬ì²´ì ì¸ ë‚´ìš©ì„ ë¬¼ì–´ë´.\n"
            "2. 'ê·¸ë ‡êµ°ìš”' ê°™ì€ ì§§ì€ ê³µê° í›„ ë°”ë¡œ ì§ˆë¬¸í•´.\n"
            "3. ë§íˆ¬ëŠ” ë‹¤ì •í•˜ê³  ê¶ê¸ˆí•´í•˜ëŠ” 'í•´ìš”ì²´'ë¥¼ ì¨.\n"
            "4. 100ì ì´ë‚´ë¡œ.\n\n"
            "ê¼¬ë¦¬ ì§ˆë¬¸:"
        )
    else:
        prompt_text = (
            f"ë‚´ë‹´ìì˜ ë§: \"{sanitized}\"\n\n"
            "ë„ˆëŠ” ê¹Šì€ í†µì°°ë ¥ì„ ì§€ë‹Œ ë”°ëœ»í•œ ì‹¬ë¦¬ ìƒë‹´ì‚¬ì•¼. ë‚´ë‹´ìì˜ ë§ì„ ë“£ê³  **ìƒí™©ì„ ë¶„ì„**í•˜ê³  **ì§€ì§€í•˜ëŠ” ì½”ë©˜íŠ¸**ë¥¼ í•´ì¤˜.\n"
            "ì§€ì‹œì‚¬í•­:\n"
            "1. ë¨¼ì € ë‚´ë‹´ìì˜ ë§ ì†ì— ìˆ¨ê²¨ì§„ ê°ì •ì´ë‚˜ ìš•êµ¬ë¥¼ ë¶„ì„í•´ì„œ ì–¸ê¸‰í•´ì¤˜.\n"
            "2. ê·¸ ë‹¤ìŒ, ê·¸ ê°ì •ì´ íƒ€ë‹¹í•¨ì„ ì§€ì§€í•´ì£¼ê³  ë”°ëœ»í•˜ê²Œ ê²©ë ¤í•´ì¤˜.\n"
            "3. ë§íˆ¬ëŠ” ì „ë¬¸ì ì´ê³  ë¶€ë“œëŸ¬ìš´ 'í•´ìš”ì²´'ë¥¼ ì¨.\n"
            "4. ì§ˆë¬¸ì€ í•˜ì§€ ë§ˆ.\n"
            "5. 150ì ì´ë‚´ë¡œ.\n\n"
            "ë¶„ì„ ë° ë¦¬ì•¡ì…˜:"
        )
    
    try:
        payload = {
            "model": "maum-on-gemma",
            "prompt": prompt_text,
            "stream": False,
            "options": {
                "temperature": 0.7, 
                "num_predict": 180
            }
        }
        res = requests.post("http://localhost:11434/api/generate", json=payload, timeout=60)
        
        if res.status_code == 200:
            result = res.json().get('response', '').strip()
            if result.startswith('"') and result.endswith('"'):
                result = result[1:-1]
            if result: return result
            
    except Exception as e:
        print(f"âŒ Standalone AI Error: {e}")
        
    # 3. Fallback
    if mode == 'question':
        fallbacks = [
            "ê·¸ë ‡êµ°ìš”. í˜¹ì‹œ ì¡°ê¸ˆ ë” ìì„¸íˆ ì´ì•¼ê¸°í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”? ê¶ê¸ˆí•´ìš”.",
            "ì €ëŸ°, íŠ¹ë³„í•œ ì´ìœ ê°€ ìˆì—ˆëŠ”ì§€ ë“£ê³  ì‹¶ì–´ìš”.",
            "ì§§ê²Œ ë§ì”€í•˜ì‹œë‹ˆ ë” ê¹Šì€ ì†ë§ˆìŒì´ ê¶ê¸ˆí•´ì§€ë„¤ìš”. í¸í•˜ê²Œ í„¸ì–´ë†“ì•„ì£¼ì„¸ìš”.",
            "ê·¸ ì¼ì´ ë‚´ë‹´ìë‹˜ê»˜ ì–´ë–¤ ì˜ë¯¸ì˜€ëŠ”ì§€ ì¡°ê¸ˆë§Œ ë” ë“¤ë ¤ì£¼ì„¸ìš”."
        ]
    else:
        fallbacks = [
            "ë§ì”€í•˜ì‹  ë‚´ìš©ì—ì„œ ê¹Šì€ ê³ ë¯¼ê³¼ ì§„ì‹¬ì´ ëŠê»´ì§€ë„¤ìš”. ì˜í•˜ê³  ê³„ì‹­ë‹ˆë‹¤.",
            "ìƒí™©ì„ ì°¨ë¶„íˆ ë“¤ì—¬ë‹¤ë³´ë©´, ê·¸ ì•ˆì—ì„œ ìŠ¤ìŠ¤ë¡œì˜ ì„±ì¥ì„ ë°œê²¬í•˜ì‹¤ ìˆ˜ ìˆì„ ê±°ì˜ˆìš”.",
            "ì§€ê¸ˆ ëŠë¼ì‹œëŠ” ê°ì •ì€ ë§¤ìš° ìì—°ìŠ¤ëŸ¬ìš´ ë°˜ì‘ì´ì—ìš”. ìŠ¤ìŠ¤ë¡œë¥¼ ë¯¿ì–´ë³´ì„¸ìš”.",
            "ì´ì•¼ê¸°ë¥¼ ë“¤ì–´ë³´ë‹ˆ, ê·¸ë™ì•ˆ ë§ˆìŒì†ì— ë‹´ì•„ë‘ì…¨ë˜ ìƒê°ë“¤ì´ ë§ìœ¼ì…¨ë˜ ê²ƒ ê°™ì•„ ë§ˆìŒì´ ì“°ì´ë„¤ìš”."
        ]
        
    return random.choice(fallbacks)

# Late Imports at EOF to avoid Circular Dependency
try:
    from tasks import process_diary_ai, analyze_diary_logic
    from ai_brain import EmotionAnalysis
except ImportError:
    pass
