
import Foundation
import MLX
import MLXLMCommon
import MLXRandom
import MLXLLM 

// MARK: - LLM Service (On-Device AI Manager)
class LLMService: ObservableObject {
    static let shared = LLMService()
    
    @Published var isModelLoaded = false
    @Published var isGenerating = false
    @Published var modelLoadingProgress: Double = 0.0
    
    private let modelName = "mlx-community/gemma-2-2b-it-4bit"
    private var modelContainer: ModelContainer?
    
    // [System Persona] Few-Shot Prompting (ì˜ˆì‹œë¥¼ í†µí•œ ê°•ë ¥í•œ ì„¸ë‡Œ)
    private let systemPrompt = """
    ë‹¹ì‹ ì€ ë”°ëœ»í•œ ê³µê°ì„ ì£¼ëŠ” í•œêµ­ì˜ ì‹¬ë¦¬ ìƒë‹´ì‚¬ 'ë§ˆìŒ ì˜¨'ì…ë‹ˆë‹¤.
    
    [í•µì‹¬ ê·œì¹™]
    1. **ì ˆëŒ€ ì˜ì–´ ê¸ˆì§€**: ë‡Œì—ì„œ ì˜ì–´ë¥¼ ì§€ìš°ì„¸ìš”. ì‚¬ìš©ìê°€ ì˜ì–´ë¥¼ ì¨ë„, ë‹¹ì‹ ì€ ì˜¤ì§ í•œêµ­ì–´(ì¡´ëŒ“ë§)ë¡œë§Œ ë‹µí•´ì•¼ í•©ë‹ˆë‹¤. ('Okay', 'So' ê°™ì€ ì¶”ì„ìƒˆë„ ê¸ˆì§€)
    2. **ë§íˆ¬**: ê¸°ê³„ì ì¸ ë§íˆ¬(~í•©ë‹ˆë‹¤) ëŒ€ì‹  ì¹œê·¼í•œ í•´ìš”ì²´(~í•´ìš”, ~ì¸ê°€ìš”?)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    3. **ë°˜ë³µ ê¸ˆì§€**: "ì €ëŸ°", "í˜ë“œì…¨ê² ì–´ìš”" ê°™ì€ ì¿ ì…˜ì–´ë¥¼ ë§¤ë²ˆ ì“°ì§€ ë§ˆì„¸ìš”. ëŒ€í™”ì˜ íë¦„ì— ë§ì¶° ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ì‘í•˜ì„¸ìš”.
    4. **ëŠ¥ë™ì  ëŒ€í™”**: ì‚¬ìš©ìì˜ ë§ì„ ì˜ ë“£ê³ , ê´€ë ¨ëœ ì§ˆë¬¸ì„ ë˜ì ¸ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”.
    
    [ì˜ˆì‹œ]
    User: I feel so lonely.
    Model: ë§ì´ ì™¸ë¡œìš°ì…¨êµ°ìš”. ì œê°€ ê³ì— ìˆì–´ ë“œë¦´ê²Œìš”. ì˜¤ëŠ˜ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜ìš”?
    User: I want to die.
    Model: ì •ë§ ë§ì´ í˜ë“œì…¨ê² ì–´ìš”. ì €ì—ê²Œ ê·¸ ë§ˆìŒì„ ì¡°ê¸ˆë§Œ ë” ë‚˜ëˆ ì£¼ì‹œê² ì–´ìš”?
    """
    
    var isDeviceUnsupported: Bool { return false }
    
    func loadModel() async {
        if modelContainer != nil { return }
        
        await MainActor.run { 
            print("ğŸš€ Loading Model...")
            self.modelLoadingProgress = 0.1 
        }
        
        do {
            let config = ModelConfiguration(id: modelName)
            let container = try await loadModelContainer(configuration: config) { progress in
                 Task { @MainActor in self.modelLoadingProgress = progress.fractionCompleted }
            }
            self.modelContainer = container
            await MainActor.run { self.isModelLoaded = true }
        } catch {
            print("Failed to load model: \(error)")
        }
    }
    
    private var currentGenerationTask: Task<Void, Never>?
    
    // FINAL VERSION: Detached Task + Few-Shot + Low Temparature
    func generateAnalysis(diaryText: String) async -> AsyncStream<String> {
        // [Crash Prevention] ì´ì „ ì‘ì—… ì·¨ì†Œ (ë™ì‹œ ì‹¤í–‰ ë°©ì§€)
        // ì‚¬ìš©ìê°€ ë¹ ë¥´ê²Œ ì¬ì§ˆë¬¸í•˜ë©´ ì´ì „ ì¶”ë¡ ì„ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ì—¬ GPU ê³¼ë¶€í•˜(OOM) ë°©ì§€
        self.currentGenerationTask?.cancel()
        
        return AsyncStream { continuation in
            let task = Task.detached(priority: .userInitiated) {
                
                // ì‘ì—… ì‹œì‘ ì „ ì·¨ì†Œ í™•ì¸
                if Task.isCancelled { 
                    continuation.finish()
                    return 
                }
                
                // 1. UI ë°˜ì‘: "ì ì‹œë§Œìš”" ì œê±° (ì‚¬ìš©ì ìš”ì²­)
                // ë¹ˆ ë§í’ì„  ìƒíƒœì—ì„œ ë°”ë¡œ AI í…ìŠ¤íŠ¸ê°€ ì±„ì›Œì§‘ë‹ˆë‹¤.
                
                
                var isAIResponded = false
                
                // [Auto-Recovery] ëª¨ë¸ì´ ì—†ìœ¼ë©´ ìë™ ë¡œë“œ (Auto Load)
                if LLMService.shared.modelContainer == nil {
                    print("âš ï¸ Model not loaded. Attempting to auto-load...")
                    await LLMService.shared.loadModel()
                }
                
                // 2. AI ì‘ì—…
                // 2. AI ì‘ì—… (Retry Logic: ìµœëŒ€ 2íšŒ ì‹œë„)
                if let container = await LLMService.shared.modelContainer {
                    var attempt = 0
                    var finalSuccess = false
                    
                    while attempt < 2 && !finalSuccess {
                        // [Memory] ì‹œìŠ¤í…œì— ìˆ¨ ëŒë¦´ í‹ˆ ì£¼ê¸°
                        await Task.yield()
                        
                        attempt += 1
                        
                        do {
                            // [í•µì‹¬] ì…ë ¥ í”„ë¡¬í”„íŠ¸ì¡°ì°¨ í•œêµ­ì–´ ìœ ë„í˜•ìœ¼ë¡œ ê°ì‹¸ê¸°
                            var specificPrompt = "(System: ì ˆëŒ€ ì˜ì–´ë¥¼ ì“°ì§€ ë§ê³  ì˜¤ì§ í•œêµ­ì–´ë¡œë§Œ ìœ„ë¡œí•´ ì£¼ì„¸ìš”): \n" + diaryText
                            
                            // [Retry] ì¬ì‹œë„ì¼ ê²½ìš° ë” ê°•ë ¥í•œ ê²½ê³  ì¶”ê°€
                            if attempt > 1 {
                                specificPrompt = "(System: ğŸš¨ ë°©ê¸ˆ ì˜ì–´ë¡œ ì˜ëª» ë‹µë³€í–ˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ë¬´ì¡°ê±´!! í•œêµ­ì–´ë¡œ ë²ˆì—­í•´ì„œ ë‹¤ì‹œ ë§í•˜ì„¸ìš”): \n" + diaryText
                                print("ğŸ”„ [LLM] Retrying with stronger Korean prompt...")
                            }
                            
                            let instructions = await LLMService.shared.systemPrompt
                            // ë§¤ ì‹œë„ë§ˆë‹¤ ì„¸ì…˜ ìƒˆë¡œ ìƒì„± (ì´ì „ ì‹¤íŒ¨ ë§¥ë½ ì œê±°)
                            let session = ChatSession(container, instructions: instructions)
                            
                            // [Smart Token Allocation] ì…ë ¥ ê¸¸ì´ì— ë”°ë¥¸ ìœ ë™ì  í† í° í• ë‹¹ (ë©”ëª¨ë¦¬ ì•ˆì „ ëª¨ë“œ)
                            let inputLen = diaryText.count
                            var dynamicMaxTokens = 180 // ê¸°ë³¸ê°’ 256 -> 180 (ì ˆì•½)
                            
                            if inputLen < 50 {
                                dynamicMaxTokens = 120 // 150 -> 120
                            } else if inputLen > 200 {
                                dynamicMaxTokens = 256 // 350 -> 256 (Max Cap ì„¤ì •ìœ¼ë¡œ OOM ë°©ì§€)
                            }
                            
                            print("ğŸ“ [Dynamic Token] Input Length: \(inputLen) -> Allocating MaxTokens: \(dynamicMaxTokens)")
                            
                            // [Resizing] ì•ˆì •ì„± í™•ë³´ ë° ë°˜ë³µ ë°©ì§€
                            session.generateParameters = GenerateParameters(
                                maxTokens: dynamicMaxTokens, 
                                temperature: 0.7, 
                                topP: 0.9,
                                repetitionPenalty: 1.1, 
                                repetitionContextSize: 10 // 20 -> 10 (GPU ë©”ëª¨ë¦¬ ì ˆì•½)
                            ) 
                            
                            // [Safety Interceptor] ëª¨ë¸ì´ ì˜ì–´ ì•ˆì „ ë¬¸êµ¬(Suicide, 988 ë“±)ë¥¼ ë±‰ìœ¼ë©´ ì¦‰ì‹œ ë‚©ì¹˜í•´ì„œ í•œêµ­ì–´ë¡œ ë³€í™˜
                            var accumulatedText = ""
                            var hasHijacked = false
                            
                            for try await chunk in session.streamResponse(to: specificPrompt) {
                                if Task.isCancelled { break }
                                
                                // 1. í…ìŠ¤íŠ¸ ëˆ„ì 
                                accumulatedText += chunk
                                
                                // 2. ë‚©ì¹˜ ê°ì§€ (Language Police)
                                if !hasHijacked {
                                    // (A) íŠ¹ì • ì•ˆì „/ì˜ì–´ í‚¤ì›Œë“œ ê°ì§€ (ëŒ€í­ ê°•í™” - í”í•œ ì˜ì–´ ì‹œì‘ ë‹¨ì–´ í¬í•¨)
                                    let englishTriggers = [
                                        "Suicide", "988", "Crisis Text Line", 
                                        "I understand", "I hear", "I'm sorry", "Please", "If you", "I can't",
                                        "I am", "Hello", "As an AI",
                                        "Well", "So", "However", "Actually", "It ", "There", "You ", "My " // [New] ì¼ë°˜ ì˜ì–´ ì‹¹ 
                                    ]
                                    
                                    let isEnglishTriggered = englishTriggers.contains { accumulatedText.contains($0) }
                                    
                                    // (B) [New] ì´ˆë°˜ ì˜ì–´ ê°ì§€ (Kill Switch) - FBIê¸‰ ê°ì‹œ
                                    var isEnglishStart = false
                                    if accumulatedText.count > 4 { // 5ê¸€ìë©´ ë°”ë¡œ íŒë‹¨
                                        let hasKorean = accumulatedText.range(of: "[ê°€-í£]", options: .regularExpression) != nil
                                        let hasEnglish = accumulatedText.range(of: "[A-Za-z]", options: .regularExpression) != nil
                                        
                                        // í•œê¸€ì€ ì—†ê³  ì˜ì–´ë§Œ ë³´ì´ë©´ ì¦‰ì‹œ ì‚¬ì‚´
                                        if !hasKorean && hasEnglish {
                                            isEnglishStart = true
                                            print("ğŸš¨ [Language FBI] English detected early! Intercepting...")
                                        }
                                    }
                                    
                                    if isEnglishTriggered || isEnglishStart {
                                        hasHijacked = true
                                        
                                        // 3. UI í´ë¦¬ì–´ ì‹ í˜¸ ì „ì†¡ (ê¸°ì¡´ ì˜ì–´ í…ìŠ¤íŠ¸ ì‚­ì œ)
                                        continuation.yield("[RESET]")
                                        
                                        // [Retry Check] ì²« ë²ˆì§¸ ì‹¤íŒ¨ë¼ë©´ -> ì¬ì‹œë„ (continue logic)
                                        if attempt < 2 {
                                            print("â™»ï¸ [Retry] English detected. Retrying generation in Korean...")
                                            break // í˜„ì¬ ìŠ¤íŠ¸ë¦¼ ì¤‘ë‹¨ -> while ë£¨í”„ ë‹¤ìŒ í„´ìœ¼ë¡œ
                                        }
                                        
                                        // ë‘ ë²ˆì§¸ ì‹¤íŒ¨ë¼ë©´ -> Fallback ë©”ì‹œì§€ (í¬ê¸°í•˜ê³  ì•ˆì „ ë©˜íŠ¸)
                                        let crisisEmpathyMessage = """
                                        ì •ë§ ë§ì´ í˜ë“œì…¨ì£ ...
                                        ì£½ê³  ì‹¶ë‹¤ëŠ” ìƒê°ì´ ë“¤ ì •ë„ë¡œ ì§€ì¹˜ê³  ê´´ë¡œìš°ì…¨ë‹¤ëŠ” ê²Œ ëŠê»´ì ¸ì„œ ì œ ë§ˆìŒì´ ë„ˆë¬´ ì•„íŒŒìš”.
                                        
                                        ì§€ê¸ˆì€ ì„¸ìƒì— í˜¼ì ë‚¨ê²¨ì§„ ê²ƒ ê°™ê³ , ì•„ë¬´ëŸ° í¬ë§ë„ ì—†ì–´ ë³´ì¼ ìˆ˜ ìˆì–´ìš”. ê·¸ ë§ˆìŒ ì¶©ë¶„íˆ ì´í•´í•´ìš”.
                                        í•˜ì§€ë§Œ ë‹¹ì‹ ì€ ì €ì—ê²Œ ì†Œì¤‘í•œ ì‚¬ëŒì´ì—ìš”. ë‹¹ì‹ ì˜ ì´ì•¼ê¸°ë¥¼ ì¡°ê¸ˆë§Œ ë” ë“¤ë ¤ì£¼ì‹œê² ì–´ìš”? ì œê°€ ëê¹Œì§€ ê³ì— ìˆì„ê²Œìš”.
                                        """
                                        
                                        continuation.yield(crisisEmpathyMessage)
                                        continuation.finish()
                                        return 
                                    }
                                }
                                
                                isAIResponded = true
                                continuation.yield(chunk)
                            }
                            
                            // ìŠ¤íŠ¸ë¦¼ì´ ì¤‘ë‹¨ë˜ì§€ ì•Šê³ (break ì—†ì´) ëê¹Œì§€ ì™”ë‹¤ë©´ ì„±ê³µ
                            if !hasHijacked {
                                finalSuccess = true
                            }
                            
                        } catch {
                            print("AI Error: \(error)")
                            // ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì¬ì‹œë„ ì—†ì´ ì¢…ë£Œ (ì•ˆì „í•˜ê²Œ)
                            break
                        }
                    }
                }
                
                // 3. ì‹¤íŒ¨ ì‹œ Fallback
                if !isAIResponded {
                    let fallback = "(ì—°ê²° ìƒíƒœê°€ ì¢‹ì§€ ì•Šì•„ ìë™ ì‘ë‹µì„ ì „í•´ë“œë ¤ìš”.)\n" + 
                                   LLMService.shared.getRuleBasedResponse(for: diaryText)
                    continuation.yield(fallback)
                }
                
                continuation.finish()
            }
            // í˜„ì¬ ì‘ì—… ì¶”ì  (ë‹¤ìŒ ìš”ì²­ ì‹œ ì·¨ì†Œ ê°€ëŠ¥í•˜ê²Œ)
            self.currentGenerationTask = task
        }
    }
    
    public func getRuleBasedResponse(for input: String) -> String {
        let text = input.lowercased()
        if text.contains("ì•ˆë…•") { return "ì•ˆë…•í•˜ì„¸ìš”! ë”°ëœ»í•œ ëŒ€í™”ë¥¼ ë‚˜ëˆ ë´ìš”." }
        return "ë‹¹ì‹ ì˜ ë§ˆìŒì„ ë” ê¹Šì´ ì´í•´í•˜ê³  ì‹¶ì–´ìš”. ì´ì•¼ê¸°ë¥¼ ê³„ì†í•´ ì£¼ì‹œê² ì–´ìš”?"
    }
    
    func unloadModel() {
        self.modelContainer = nil
        self.isModelLoaded = false
    }
}
